{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(directory):\n",
    "    feature = []\n",
    "    label = []\n",
    "    for foldername in os.listdir(directory):\n",
    "        folder = os.path.join(directory, foldername)\n",
    "        if os.path.isdir(folder):\n",
    "            files = os.listdir(folder)\n",
    "            for filename in files:\n",
    "                rel_path = os.path.join(directory, foldername, filename)\n",
    "                temp_label = filename.split('.')[0].split('_')[0]\n",
    "                if 'a' in temp_label:\n",
    "                    label = np.append(label,'alcoholic')\n",
    "                else:\n",
    "                    label = np.append(label,'control')\n",
    "                \n",
    "                df_data = np.loadtxt(rel_path, delimiter=\",\")\n",
    "                feature.append(df_data.T)\n",
    "    return np.array(feature), np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(path):\n",
    "    # loading extracted feature & label\n",
    "    x, y = get_dataset(path)\n",
    "    y = pd.DataFrame(y)\n",
    "    \n",
    "    # Encode the labels\n",
    "    label_map = {\"alcoholic\": 1, \"control\": 0}\n",
    "    y[0] = y[0].map(label_map)\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x, y[0]))\n",
    "    dataset = dataset.shuffle(len(y[0])).batch(32)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = keras.models.Sequential()\n",
    "\n",
    "    model.add(layers.Input(shape=(366,)))\n",
    "    model.add(layers.Reshape((366, 1)))\n",
    "\n",
    "    model.add(layers.Conv1D(filters=16, kernel_size=4, activation=\"relu\"))\n",
    "    model.add(layers.MaxPooling1D(pool_size=2))\n",
    "\n",
    "    model.add(layers.Conv1D(filters=8, kernel_size=2, activation=\"relu\"))\n",
    "    model.add(layers.MaxPooling1D(pool_size=2))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    model.add(layers.Dense(2160, activation=\"relu\"))\n",
    "\n",
    "    model.add(layers.Dropout(0.2))\n",
    "\n",
    "    model.add(layers.Dense(1080, activation=\"relu\"))\n",
    "\n",
    "    model.add(layers.Dropout(0.2))\n",
    "\n",
    "    model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = get_batch('../Features/smni_cmi_test_feature_256')\n",
    "\n",
    "train_size = int(len(list(train.as_numpy_iterator()))*0.8)\n",
    "\n",
    "train_ds = train.take(train_size)\n",
    "val_ds = train.skip(train_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(32, 366), dtype=float64, numpy=\n",
      "array([[7.06712722e+03, 7.84701434e+00, 2.87291905e+02, ...,\n",
      "        2.93989709e+00, 1.23154756e+01, 9.87707358e+00],\n",
      "       [1.57220802e+03, 8.31488066e-01, 3.35143489e+01, ...,\n",
      "        1.27694243e+01, 4.56108024e+01, 7.93976020e+01],\n",
      "       [7.08962869e+02, 1.94986418e-01, 6.80302927e+00, ...,\n",
      "        8.83749177e-01, 1.64077697e+00, 3.55619653e+00],\n",
      "       ...,\n",
      "       [2.57953899e+04, 7.08163742e-01, 3.01469481e+01, ...,\n",
      "        5.01447841e+00, 1.95511996e+01, 1.12378881e+01],\n",
      "       [6.51052433e+04, 3.89568136e+00, 1.28917402e+02, ...,\n",
      "        8.70762447e+00, 2.30449212e+01, 3.04236546e+01],\n",
      "       [4.55321244e+04, 2.14535841e+00, 1.09387208e+02, ...,\n",
      "        7.82359311e+00, 1.08454381e+01, 3.77817210e+01]])>, <tf.Tensor: shape=(32,), dtype=int64, numpy=\n",
      "array([0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
      "       0, 0, 1, 1, 1, 1, 1, 0, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(32, 366), dtype=float64, numpy=\n",
      "array([[2.67262148e+05, 3.55796605e+05, 1.92459860e+06, ...,\n",
      "        3.12612924e+00, 8.60574782e+00, 3.93979652e+00],\n",
      "       [4.64136643e+04, 1.88799940e+00, 5.82150285e+01, ...,\n",
      "        3.44507304e+00, 1.79417388e+01, 1.05160456e+01],\n",
      "       [3.03491951e+03, 6.06287652e+00, 2.08692227e+02, ...,\n",
      "        5.13192132e+00, 1.65935803e+01, 7.38129661e+00],\n",
      "       ...,\n",
      "       [1.12027181e+06, 5.93452689e-01, 1.56039825e+01, ...,\n",
      "        2.14509820e+00, 2.59871952e+01, 1.15765165e+02],\n",
      "       [1.72671512e+06, 1.00451782e+01, 3.75515617e+02, ...,\n",
      "        2.80152274e+00, 1.33788697e+01, 5.36421037e+01],\n",
      "       [9.62147237e+02, 1.65778502e+00, 5.73299929e+01, ...,\n",
      "        1.25387314e+00, 1.78119191e+00, 5.11290843e+00]])>, <tf.Tensor: shape=(32,), dtype=int64, numpy=\n",
      "array([1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(32, 366), dtype=float64, numpy=\n",
      "array([[7.18592921e+03, 3.23607358e-01, 1.15227912e+01, ...,\n",
      "        2.04995645e+00, 1.62166516e+01, 3.82303101e+01],\n",
      "       [9.12712424e+03, 1.04580948e+00, 3.67801059e+01, ...,\n",
      "        3.88369238e-01, 2.20049532e+00, 3.56745787e+00],\n",
      "       [1.25315558e+04, 1.13342114e+00, 5.87944622e+01, ...,\n",
      "        2.61845443e+00, 1.02666002e+01, 4.45751495e+01],\n",
      "       ...,\n",
      "       [2.12264698e+03, 3.11291565e+00, 1.15359026e+02, ...,\n",
      "        5.71402220e+00, 3.76835656e+01, 5.42686890e+02],\n",
      "       [1.85586948e+05, 1.65572124e+01, 3.84852173e+02, ...,\n",
      "        1.44962271e+01, 1.77445667e+02, 2.09004501e+02],\n",
      "       [8.78941527e+02, 6.02803071e-01, 2.30900296e+01, ...,\n",
      "        9.45339151e-01, 9.41596730e+00, 5.15553131e+00]])>, <tf.Tensor: shape=(32,), dtype=int64, numpy=\n",
      "array([0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
      "       0, 0, 0, 1, 0, 1, 0, 1, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(24, 366), dtype=float64, numpy=\n",
      "array([[1.54663830e+03, 1.65483103e-01, 5.76404933e+00, ...,\n",
      "        7.72858758e-01, 3.24130310e+00, 2.52805024e+00],\n",
      "       [3.80854898e+03, 7.81473263e+00, 1.81045302e+02, ...,\n",
      "        5.31596899e+00, 1.48579062e+01, 3.07983349e+00],\n",
      "       [8.43214959e+05, 4.34746927e+05, 2.42866171e+06, ...,\n",
      "        1.19765499e+00, 1.22989117e+00, 4.75348365e-01],\n",
      "       ...,\n",
      "       [8.04276369e+03, 6.61428294e-01, 1.65305390e+01, ...,\n",
      "        4.47688715e+00, 1.01933976e+01, 3.12443757e+00],\n",
      "       [6.03943243e+03, 5.71573790e+00, 3.24474746e+02, ...,\n",
      "        6.91634757e+01, 2.43372745e+01, 7.54745418e+01],\n",
      "       [1.41871284e+04, 3.33627126e+00, 1.71981941e+02, ...,\n",
      "        3.95566637e+01, 4.29158826e+02, 2.53258151e+02]])>, <tf.Tensor: shape=(24,), dtype=int64, numpy=\n",
      "array([0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1,\n",
      "       1, 0], dtype=int64)>)\n"
     ]
    }
   ],
   "source": [
    "for x in val_ds:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " reshape_6 (Reshape)         (None, 366, 1)            0         \n",
      "                                                                 \n",
      " conv1d_12 (Conv1D)          (None, 363, 16)           80        \n",
      "                                                                 \n",
      " max_pooling1d_12 (MaxPoolin  (None, 181, 16)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_13 (Conv1D)          (None, 180, 8)            264       \n",
      "                                                                 \n",
      " max_pooling1d_13 (MaxPoolin  (None, 90, 8)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 720)               0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 2160)              1557360   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 2160)              0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1080)              2333880   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1080)              0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 1)                 1081      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,892,665\n",
      "Trainable params: 3,892,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "15/15 [==============================] - 3s 66ms/step - loss: 7996.4927 - accuracy: 0.5083 - val_loss: 0.7009 - val_accuracy: 0.4167\n",
      "Epoch 2/200\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.6942 - accuracy: 0.5000 - val_loss: 0.6926 - val_accuracy: 0.5167\n",
      "Epoch 3/200\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.6950 - accuracy: 0.4875 - val_loss: 0.6926 - val_accuracy: 0.5167\n",
      "Epoch 4/200\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.6936 - accuracy: 0.4979 - val_loss: 0.6930 - val_accuracy: 0.5083\n",
      "Epoch 5/200\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.6932 - accuracy: 0.5042 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 6/200\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.6930 - accuracy: 0.5146 - val_loss: 0.6930 - val_accuracy: 0.5083\n",
      "Epoch 7/200\n",
      "15/15 [==============================] - 1s 42ms/step - loss: 0.6932 - accuracy: 0.5063 - val_loss: 0.6944 - val_accuracy: 0.4667\n",
      "Epoch 8/200\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.6935 - accuracy: 0.4938 - val_loss: 0.6923 - val_accuracy: 0.5333\n",
      "Epoch 9/200\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.6936 - accuracy: 0.5063 - val_loss: 0.6933 - val_accuracy: 0.4833\n",
      "Epoch 10/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.6930 - accuracy: 0.5125 - val_loss: 0.6938 - val_accuracy: 0.4583\n",
      "Epoch 11/200\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.6933 - accuracy: 0.5021 - val_loss: 0.6930 - val_accuracy: 0.5083\n",
      "Epoch 12/200\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6941 - val_accuracy: 0.4500\n",
      "Epoch 13/200\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.6936 - accuracy: 0.4729 - val_loss: 0.6927 - val_accuracy: 0.5333\n",
      "Epoch 14/200\n",
      "15/15 [==============================] - 1s 33ms/step - loss: 0.6931 - accuracy: 0.5063 - val_loss: 0.6938 - val_accuracy: 0.3917\n",
      "Epoch 15/200\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.6932 - accuracy: 0.4896 - val_loss: 0.6926 - val_accuracy: 0.5917\n",
      "Epoch 16/200\n",
      "15/15 [==============================] - 1s 46ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.4917\n",
      "Epoch 17/200\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.6932 - accuracy: 0.4938 - val_loss: 0.6929 - val_accuracy: 0.5583\n",
      "Epoch 18/200\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.6932 - accuracy: 0.4750 - val_loss: 0.6932 - val_accuracy: 0.4667\n",
      "Epoch 19/200\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.6932 - accuracy: 0.4625 - val_loss: 0.6930 - val_accuracy: 0.5583\n",
      "Epoch 20/200\n",
      "15/15 [==============================] - 1s 56ms/step - loss: 0.6931 - accuracy: 0.4958 - val_loss: 0.6931 - val_accuracy: 0.5250\n",
      "Epoch 21/200\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.6932 - accuracy: 0.4563 - val_loss: 0.6931 - val_accuracy: 0.5333\n",
      "Epoch 22/200\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.6932 - accuracy: 0.4729 - val_loss: 0.6932 - val_accuracy: 0.4667\n",
      "Epoch 23/200\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.6932 - accuracy: 0.4792 - val_loss: 0.6932 - val_accuracy: 0.4917\n",
      "Epoch 24/200\n",
      "15/15 [==============================] - 1s 47ms/step - loss: 0.6932 - accuracy: 0.4833 - val_loss: 0.6931 - val_accuracy: 0.5083\n",
      "Epoch 25/200\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.6932 - accuracy: 0.4563 - val_loss: 0.6932 - val_accuracy: 0.4583\n",
      "Epoch 26/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.6931 - accuracy: 0.5083 - val_loss: 0.6931 - val_accuracy: 0.5167\n",
      "Epoch 27/200\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.6931 - accuracy: 0.5104 - val_loss: 0.6933 - val_accuracy: 0.4750\n",
      "Epoch 28/200\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6933 - val_accuracy: 0.4750\n",
      "Epoch 29/200\n",
      "15/15 [==============================] - 1s 42ms/step - loss: 0.6933 - accuracy: 0.4979 - val_loss: 0.6932 - val_accuracy: 0.4917\n",
      "Epoch 30/200\n",
      "15/15 [==============================] - 1s 41ms/step - loss: 0.6933 - accuracy: 0.4833 - val_loss: 0.6931 - val_accuracy: 0.5167\n",
      "Epoch 31/200\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.6931 - accuracy: 0.5042 - val_loss: 0.6931 - val_accuracy: 0.5083\n",
      "Epoch 32/200\n",
      "15/15 [==============================] - 1s 38ms/step - loss: 0.6932 - accuracy: 0.5063 - val_loss: 0.6932 - val_accuracy: 0.4917\n",
      "Epoch 33/200\n",
      "15/15 [==============================] - 1s 45ms/step - loss: 0.6932 - accuracy: 0.4896 - val_loss: 0.6932 - val_accuracy: 0.4917\n",
      "Epoch 34/200\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.6932 - accuracy: 0.4833 - val_loss: 0.6933 - val_accuracy: 0.4333\n",
      "Epoch 35/200\n",
      "15/15 [==============================] - 1s 41ms/step - loss: 0.6932 - accuracy: 0.5083 - val_loss: 0.6931 - val_accuracy: 0.4833\n",
      "Epoch 36/200\n",
      "15/15 [==============================] - 1s 45ms/step - loss: 0.6931 - accuracy: 0.4750 - val_loss: 0.6931 - val_accuracy: 0.5167\n",
      "Epoch 37/200\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5583\n",
      "Epoch 38/200\n",
      "15/15 [==============================] - 1s 42ms/step - loss: 0.6931 - accuracy: 0.5125 - val_loss: 0.6932 - val_accuracy: 0.4917\n",
      "Epoch 39/200\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.6932 - accuracy: 0.4812 - val_loss: 0.6932 - val_accuracy: 0.4917\n",
      "Epoch 40/200\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.6932 - accuracy: 0.4792 - val_loss: 0.6931 - val_accuracy: 0.4667\n",
      "Epoch 41/200\n",
      "15/15 [==============================] - 1s 33ms/step - loss: 0.6932 - accuracy: 0.4458 - val_loss: 0.6931 - val_accuracy: 0.4917\n",
      "Epoch 42/200\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.6932 - accuracy: 0.4875 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 43/200\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.6931 - accuracy: 0.4958 - val_loss: 0.6931 - val_accuracy: 0.5250\n",
      "Epoch 44/200\n",
      "15/15 [==============================] - 1s 44ms/step - loss: 0.6932 - accuracy: 0.4938 - val_loss: 0.6932 - val_accuracy: 0.4833\n",
      "Epoch 45/200\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.6932 - accuracy: 0.4771 - val_loss: 0.6932 - val_accuracy: 0.4917\n",
      "Epoch 46/200\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.6932 - accuracy: 0.4854 - val_loss: 0.6931 - val_accuracy: 0.5583\n",
      "Epoch 47/200\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.6932 - accuracy: 0.4750 - val_loss: 0.6932 - val_accuracy: 0.4583\n",
      "Epoch 48/200\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.6932 - accuracy: 0.5188 - val_loss: 0.6931 - val_accuracy: 0.5083\n",
      "Epoch 49/200\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6930 - val_accuracy: 0.5417\n",
      "Epoch 50/200\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.6932 - accuracy: 0.5042 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 51/200\n",
      "15/15 [==============================] - 1s 38ms/step - loss: 0.6933 - accuracy: 0.4833 - val_loss: 0.6931 - val_accuracy: 0.5167\n",
      "Epoch 52/200\n",
      "15/15 [==============================] - 1s 33ms/step - loss: 0.6932 - accuracy: 0.4708 - val_loss: 0.6931 - val_accuracy: 0.5083\n",
      "Epoch 53/200\n",
      "15/15 [==============================] - 0s 34ms/step - loss: 0.6931 - accuracy: 0.5125 - val_loss: 0.6932 - val_accuracy: 0.4750\n",
      "Epoch 54/200\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.6932 - accuracy: 0.5083 - val_loss: 0.6930 - val_accuracy: 0.5250\n",
      "Epoch 55/200\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.6932 - accuracy: 0.5042 - val_loss: 0.6930 - val_accuracy: 0.5250\n",
      "Epoch 56/200\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.6933 - accuracy: 0.4854 - val_loss: 0.6933 - val_accuracy: 0.4833\n",
      "Epoch 57/200\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.6930 - accuracy: 0.5208 - val_loss: 0.6932 - val_accuracy: 0.4917\n",
      "Epoch 58/200\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.6932 - accuracy: 0.4917 - val_loss: 0.6936 - val_accuracy: 0.4333\n",
      "Epoch 59/200\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.6931 - accuracy: 0.5063 - val_loss: 0.6933 - val_accuracy: 0.4750\n",
      "Epoch 60/200\n",
      "15/15 [==============================] - 0s 34ms/step - loss: 0.6931 - accuracy: 0.5042 - val_loss: 0.6927 - val_accuracy: 0.5500\n",
      "Epoch 61/200\n",
      "15/15 [==============================] - 1s 44ms/step - loss: 0.6932 - accuracy: 0.4979 - val_loss: 0.6930 - val_accuracy: 0.5167\n",
      "Epoch 62/200\n",
      "15/15 [==============================] - 1s 43ms/step - loss: 0.6933 - accuracy: 0.4812 - val_loss: 0.6928 - val_accuracy: 0.5750\n",
      "Epoch 63/200\n",
      "15/15 [==============================] - 1s 48ms/step - loss: 0.6932 - accuracy: 0.4958 - val_loss: 0.6934 - val_accuracy: 0.4250\n",
      "Epoch 64/200\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.6931 - accuracy: 0.5083 - val_loss: 0.6934 - val_accuracy: 0.4417\n",
      "Epoch 65/200\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 0.6932 - accuracy: 0.4979 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 66/200\n",
      "15/15 [==============================] - 1s 41ms/step - loss: 0.6932 - accuracy: 0.4979 - val_loss: 0.6932 - val_accuracy: 0.4917\n",
      "Epoch 67/200\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 0.6931 - accuracy: 0.5042 - val_loss: 0.6931 - val_accuracy: 0.5083\n",
      "Epoch 68/200\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.6930 - accuracy: 0.5229 - val_loss: 0.6928 - val_accuracy: 0.5667\n",
      "Epoch 69/200\n",
      "15/15 [==============================] - 0s 34ms/step - loss: 0.6933 - accuracy: 0.4896 - val_loss: 0.6930 - val_accuracy: 0.5250\n",
      "Epoch 70/200\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.6932 - accuracy: 0.5063 - val_loss: 0.6933 - val_accuracy: 0.4750\n",
      "Epoch 71/200\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.6933 - accuracy: 0.4875 - val_loss: 0.6929 - val_accuracy: 0.5750\n",
      "Epoch 72/200\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.6931 - accuracy: 0.4958 - val_loss: 0.6930 - val_accuracy: 0.5333\n",
      "Epoch 73/200\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.6932 - accuracy: 0.4917 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 74/200\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.6932 - accuracy: 0.4854 - val_loss: 0.6931 - val_accuracy: 0.5333\n",
      "Epoch 75/200\n",
      "15/15 [==============================] - 1s 44ms/step - loss: 0.6932 - accuracy: 0.5125 - val_loss: 0.6931 - val_accuracy: 0.5083\n",
      "Epoch 76/200\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.6931 - accuracy: 0.5063 - val_loss: 0.6927 - val_accuracy: 0.5583\n",
      "Epoch 77/200\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.6932 - accuracy: 0.4896 - val_loss: 0.6935 - val_accuracy: 0.4500\n",
      "Epoch 78/200\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.6932 - accuracy: 0.4958 - val_loss: 0.6934 - val_accuracy: 0.4417\n",
      "Epoch 79/200\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.6931 - accuracy: 0.5146 - val_loss: 0.6932 - val_accuracy: 0.4833\n",
      "Epoch 80/200\n",
      "15/15 [==============================] - 1s 45ms/step - loss: 0.6931 - accuracy: 0.5042 - val_loss: 0.6930 - val_accuracy: 0.5167\n",
      "Epoch 81/200\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.6931 - accuracy: 0.5104 - val_loss: 0.6928 - val_accuracy: 0.5417\n",
      "Epoch 82/200\n",
      "15/15 [==============================] - 1s 43ms/step - loss: 0.6930 - accuracy: 0.5188 - val_loss: 0.6941 - val_accuracy: 0.4083\n",
      "Epoch 83/200\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.6932 - accuracy: 0.4938 - val_loss: 0.6928 - val_accuracy: 0.5417\n",
      "Epoch 84/200\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.6933 - accuracy: 0.4833 - val_loss: 0.6934 - val_accuracy: 0.4667\n",
      "Epoch 85/200\n",
      "15/15 [==============================] - 1s 43ms/step - loss: 0.6932 - accuracy: 0.5021 - val_loss: 0.6934 - val_accuracy: 0.4667\n",
      "Epoch 86/200\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.6933 - accuracy: 0.4875 - val_loss: 0.6931 - val_accuracy: 0.5167\n",
      "Epoch 87/200\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5083\n",
      "Epoch 88/200\n",
      "15/15 [==============================] - 1s 45ms/step - loss: 0.6931 - accuracy: 0.5063 - val_loss: 0.6935 - val_accuracy: 0.4250\n",
      "Epoch 89/200\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.6931 - accuracy: 0.4917 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 90/200\n",
      "15/15 [==============================] - 1s 46ms/step - loss: 0.6931 - accuracy: 0.5125 - val_loss: 0.6930 - val_accuracy: 0.5417\n",
      "Epoch 91/200\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.6932 - accuracy: 0.4938 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 92/200\n",
      "15/15 [==============================] - 0s 34ms/step - loss: 0.6932 - accuracy: 0.4979 - val_loss: 0.6933 - val_accuracy: 0.4750\n",
      "Epoch 93/200\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.6933 - accuracy: 0.4896 - val_loss: 0.6931 - val_accuracy: 0.5250\n",
      "Epoch 94/200\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.6932 - accuracy: 0.4938 - val_loss: 0.6932 - val_accuracy: 0.4583\n",
      "Epoch 95/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.6932 - accuracy: 0.4729 - val_loss: 0.6932 - val_accuracy: 0.4833\n",
      "Epoch 96/200\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.6931 - accuracy: 0.5125 - val_loss: 0.6931 - val_accuracy: 0.4833\n",
      "Epoch 97/200\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.6932 - accuracy: 0.4917 - val_loss: 0.6932 - val_accuracy: 0.4583\n",
      "Epoch 98/200\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.6932 - accuracy: 0.5021 - val_loss: 0.6932 - val_accuracy: 0.4750\n",
      "Epoch 99/200\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.6932 - accuracy: 0.4688 - val_loss: 0.6931 - val_accuracy: 0.5250\n",
      "Epoch 100/200\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.6932 - accuracy: 0.4667 - val_loss: 0.6931 - val_accuracy: 0.5083\n",
      "Epoch 101/200\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.6931 - accuracy: 0.4958 - val_loss: 0.6931 - val_accuracy: 0.5167\n",
      "Epoch 102/200\n",
      "15/15 [==============================] - 1s 45ms/step - loss: 0.6932 - accuracy: 0.4979 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 103/200\n",
      "15/15 [==============================] - 1s 42ms/step - loss: 0.6931 - accuracy: 0.5083 - val_loss: 0.6932 - val_accuracy: 0.4833\n",
      "Epoch 104/200\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5167\n",
      "Epoch 105/200\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.6932 - accuracy: 0.5042 - val_loss: 0.6929 - val_accuracy: 0.5667\n",
      "Epoch 106/200\n",
      "15/15 [==============================] - 1s 38ms/step - loss: 0.6931 - accuracy: 0.5021 - val_loss: 0.6933 - val_accuracy: 0.4583\n",
      "Epoch 107/200\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.6931 - accuracy: 0.5083 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 108/200\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6932 - accuracy: 0.4896 - val_loss: 0.6932 - val_accuracy: 0.4750\n",
      "Epoch 109/200\n",
      "15/15 [==============================] - 1s 32ms/step - loss: 0.6931 - accuracy: 0.5042 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 110/200\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.6931 - accuracy: 0.5021 - val_loss: 0.6935 - val_accuracy: 0.4333\n",
      "Epoch 111/200\n",
      "15/15 [==============================] - 1s 32ms/step - loss: 0.6932 - accuracy: 0.4875 - val_loss: 0.6933 - val_accuracy: 0.4750\n",
      "Epoch 112/200\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.6932 - accuracy: 0.4917 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 113/200\n",
      "15/15 [==============================] - 1s 33ms/step - loss: 0.6932 - accuracy: 0.4938 - val_loss: 0.6931 - val_accuracy: 0.5333\n",
      "Epoch 114/200\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6932 - accuracy: 0.4583 - val_loss: 0.6931 - val_accuracy: 0.5083\n",
      "Epoch 115/200\n",
      "15/15 [==============================] - 1s 41ms/step - loss: 0.6932 - accuracy: 0.4958 - val_loss: 0.6931 - val_accuracy: 0.5333\n",
      "Epoch 116/200\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.6931 - accuracy: 0.5063 - val_loss: 0.6931 - val_accuracy: 0.5083\n",
      "Epoch 117/200\n",
      "15/15 [==============================] - 1s 38ms/step - loss: 0.6931 - accuracy: 0.5063 - val_loss: 0.6932 - val_accuracy: 0.4917\n",
      "Epoch 118/200\n",
      "15/15 [==============================] - 1s 47ms/step - loss: 0.6932 - accuracy: 0.4938 - val_loss: 0.6931 - val_accuracy: 0.5167\n",
      "Epoch 119/200\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.6932 - accuracy: 0.4375 - val_loss: 0.6932 - val_accuracy: 0.4500\n",
      "Epoch 120/200\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.6931 - accuracy: 0.4979 - val_loss: 0.6930 - val_accuracy: 0.5417\n",
      "Epoch 121/200\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.6932 - accuracy: 0.4896 - val_loss: 0.6932 - val_accuracy: 0.4750\n",
      "Epoch 122/200\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.6932 - accuracy: 0.4896 - val_loss: 0.6931 - val_accuracy: 0.5167\n",
      "Epoch 123/200\n",
      "15/15 [==============================] - 1s 33ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.4917\n",
      "Epoch 124/200\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.6932 - accuracy: 0.4938 - val_loss: 0.6930 - val_accuracy: 0.5333\n",
      "Epoch 125/200\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.6931 - accuracy: 0.5146 - val_loss: 0.6931 - val_accuracy: 0.5167\n",
      "Epoch 126/200\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6932 - accuracy: 0.5104 - val_loss: 0.6938 - val_accuracy: 0.3917\n",
      "Epoch 127/200\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.6931 - accuracy: 0.5063 - val_loss: 0.6925 - val_accuracy: 0.5917\n",
      "Epoch 128/200\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.6931 - accuracy: 0.5104 - val_loss: 0.6936 - val_accuracy: 0.4417\n",
      "Epoch 129/200\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.6933 - accuracy: 0.4917 - val_loss: 0.6931 - val_accuracy: 0.5083\n",
      "Epoch 130/200\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.6932 - accuracy: 0.4875 - val_loss: 0.6930 - val_accuracy: 0.5333\n",
      "Epoch 131/200\n",
      "15/15 [==============================] - 1s 38ms/step - loss: 0.6932 - accuracy: 0.4896 - val_loss: 0.6931 - val_accuracy: 0.5167\n",
      "Epoch 132/200\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6932 - accuracy: 0.4646 - val_loss: 0.6932 - val_accuracy: 0.4667\n",
      "Epoch 133/200\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.6932 - accuracy: 0.4750 - val_loss: 0.6930 - val_accuracy: 0.5417\n",
      "Epoch 134/200\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.6932 - accuracy: 0.4833 - val_loss: 0.6932 - val_accuracy: 0.4750\n",
      "Epoch 135/200\n",
      "15/15 [==============================] - 1s 33ms/step - loss: 0.6932 - accuracy: 0.4646 - val_loss: 0.6931 - val_accuracy: 0.5917\n",
      "Epoch 136/200\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.6932 - accuracy: 0.4750 - val_loss: 0.6932 - val_accuracy: 0.4750\n",
      "Epoch 137/200\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.6932 - accuracy: 0.5042 - val_loss: 0.6932 - val_accuracy: 0.4500\n",
      "Epoch 138/200\n",
      "15/15 [==============================] - 1s 43ms/step - loss: 0.6931 - accuracy: 0.5167 - val_loss: 0.6932 - val_accuracy: 0.4333\n",
      "Epoch 139/200\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.6932 - accuracy: 0.4750 - val_loss: 0.6932 - val_accuracy: 0.4667\n",
      "Epoch 140/200\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.6931 - accuracy: 0.5229 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 141/200\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.6932 - accuracy: 0.4854 - val_loss: 0.6931 - val_accuracy: 0.5250\n",
      "Epoch 142/200\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.6931 - accuracy: 0.4979 - val_loss: 0.6931 - val_accuracy: 0.5083\n",
      "Epoch 143/200\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6932 - accuracy: 0.5125 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 144/200\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.6932 - accuracy: 0.4958 - val_loss: 0.6932 - val_accuracy: 0.4750\n",
      "Epoch 145/200\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.6932 - accuracy: 0.4833 - val_loss: 0.6932 - val_accuracy: 0.4917\n",
      "Epoch 146/200\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.6932 - accuracy: 0.4292 - val_loss: 0.6932 - val_accuracy: 0.4667\n",
      "Epoch 147/200\n",
      "15/15 [==============================] - 1s 41ms/step - loss: 0.6931 - accuracy: 0.4979 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 148/200\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.6932 - accuracy: 0.4812 - val_loss: 0.6932 - val_accuracy: 0.4917\n",
      "Epoch 149/200\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.6932 - accuracy: 0.4771 - val_loss: 0.6931 - val_accuracy: 0.5500\n",
      "Epoch 150/200\n",
      "15/15 [==============================] - 1s 45ms/step - loss: 0.6931 - accuracy: 0.5208 - val_loss: 0.6931 - val_accuracy: 0.5083\n",
      "Epoch 151/200\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.6931 - accuracy: 0.5063 - val_loss: 0.6932 - val_accuracy: 0.4917\n",
      "Epoch 152/200\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.6932 - accuracy: 0.4896 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 153/200\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.6932 - accuracy: 0.4833 - val_loss: 0.6932 - val_accuracy: 0.4667\n",
      "Epoch 154/200\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.6932 - accuracy: 0.4667 - val_loss: 0.6931 - val_accuracy: 0.5167\n",
      "Epoch 155/200\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.6931 - accuracy: 0.5146 - val_loss: 0.6931 - val_accuracy: 0.5167\n",
      "Epoch 156/200\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.6932 - accuracy: 0.4979 - val_loss: 0.6928 - val_accuracy: 0.5917\n",
      "Epoch 157/200\n",
      "15/15 [==============================] - 1s 32ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.4500\n",
      "Epoch 158/200\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.6932 - accuracy: 0.5125 - val_loss: 0.6930 - val_accuracy: 0.5583\n",
      "Epoch 159/200\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.4750\n",
      "Epoch 160/200\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.6931 - accuracy: 0.5063 - val_loss: 0.6931 - val_accuracy: 0.5083\n",
      "Epoch 161/200\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6933 - val_accuracy: 0.4417\n",
      "Epoch 162/200\n",
      "12/15 [=======================>......] - ETA: 0s - loss: 0.6931 - accuracy: 0.5104"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_ds, epochs=200, validation_data=(val_ds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skripsi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(directory):\n",
    "    feature = []\n",
    "    label = []\n",
    "    for foldername in os.listdir(directory):\n",
    "        folder = os.path.join(directory, foldername)\n",
    "        if os.path.isdir(folder):\n",
    "            files = os.listdir(folder)\n",
    "            for filename in files:\n",
    "                rel_path = os.path.join(directory, foldername, filename)\n",
    "                temp_label = filename.split('.')[0].split('_')[0]\n",
    "                if 'a' in temp_label:\n",
    "                    label = np.append(label,'alcoholic')\n",
    "                else:\n",
    "                    label = np.append(label,'control')\n",
    "                \n",
    "                df_data = np.loadtxt(rel_path, delimiter=\",\")\n",
    "                feature.append(df_data.T)\n",
    "    return np.array(feature), np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(path):\n",
    "    # loading extracted feature & label\n",
    "    x, y = get_dataset(path)\n",
    "    y = pd.DataFrame(y)\n",
    "    \n",
    "    # Encode the labels\n",
    "    label_map = {\"alcoholic\": 1, \"control\": 0}\n",
    "    y[0] = y[0].map(label_map)\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x, y[0]))\n",
    "    dataset = dataset.shuffle(len(y[0])).batch(32)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    input_layer = keras.Input(shape=(366, 1))\n",
    "\n",
    "    x = layers.Conv1D(\n",
    "        filters=32, kernel_size=3, strides=2, activation=\"relu\", padding=\"same\"\n",
    "    )(input_layer)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Conv1D(\n",
    "        filters=64, kernel_size=3, strides=2, activation=\"relu\", padding=\"same\"\n",
    "    )(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Conv1D(\n",
    "        filters=128, kernel_size=5, strides=2, activation=\"relu\", padding=\"same\"\n",
    "    )(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Conv1D(\n",
    "        filters=256, kernel_size=5, strides=2, activation=\"relu\", padding=\"same\"\n",
    "    )(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Conv1D(\n",
    "        filters=512, kernel_size=7, strides=2, activation=\"relu\", padding=\"same\"\n",
    "    )(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Conv1D(\n",
    "        filters=1024, kernel_size=7, strides=2, activation=\"relu\", padding=\"same\"\n",
    "    )(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "\n",
    "    x = layers.Dense(4096, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "\n",
    "    x = layers.Dense(\n",
    "        2048, activation=\"relu\", kernel_regularizer=keras.regularizers.L2()\n",
    "    )(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "\n",
    "    x = layers.Dense(\n",
    "        1024, activation=\"relu\", kernel_regularizer=keras.regularizers.L2()\n",
    "    )(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Dense(\n",
    "        128, activation=\"relu\", kernel_regularizer=keras.regularizers.L2()\n",
    "    )(x)\n",
    "    output_layer = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    return keras.Model(inputs=input_layer, outputs=output_layer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = get_batch('../Features/smni_cmi_test_feature_256')\n",
    "\n",
    "train_size = int(len(list(train.as_numpy_iterator()))*0.8)\n",
    "\n",
    "train_ds = train.take(train_size)\n",
    "val_ds = train.skip(train_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(32, 366), dtype=float64, numpy=\n",
      "array([[7.06712722e+03, 7.84701434e+00, 2.87291905e+02, ...,\n",
      "        2.93989709e+00, 1.23154756e+01, 9.87707358e+00],\n",
      "       [1.57220802e+03, 8.31488066e-01, 3.35143489e+01, ...,\n",
      "        1.27694243e+01, 4.56108024e+01, 7.93976020e+01],\n",
      "       [7.08962869e+02, 1.94986418e-01, 6.80302927e+00, ...,\n",
      "        8.83749177e-01, 1.64077697e+00, 3.55619653e+00],\n",
      "       ...,\n",
      "       [2.57953899e+04, 7.08163742e-01, 3.01469481e+01, ...,\n",
      "        5.01447841e+00, 1.95511996e+01, 1.12378881e+01],\n",
      "       [6.51052433e+04, 3.89568136e+00, 1.28917402e+02, ...,\n",
      "        8.70762447e+00, 2.30449212e+01, 3.04236546e+01],\n",
      "       [4.55321244e+04, 2.14535841e+00, 1.09387208e+02, ...,\n",
      "        7.82359311e+00, 1.08454381e+01, 3.77817210e+01]])>, <tf.Tensor: shape=(32,), dtype=int64, numpy=\n",
      "array([0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
      "       0, 0, 1, 1, 1, 1, 1, 0, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(32, 366), dtype=float64, numpy=\n",
      "array([[2.67262148e+05, 3.55796605e+05, 1.92459860e+06, ...,\n",
      "        3.12612924e+00, 8.60574782e+00, 3.93979652e+00],\n",
      "       [4.64136643e+04, 1.88799940e+00, 5.82150285e+01, ...,\n",
      "        3.44507304e+00, 1.79417388e+01, 1.05160456e+01],\n",
      "       [3.03491951e+03, 6.06287652e+00, 2.08692227e+02, ...,\n",
      "        5.13192132e+00, 1.65935803e+01, 7.38129661e+00],\n",
      "       ...,\n",
      "       [1.12027181e+06, 5.93452689e-01, 1.56039825e+01, ...,\n",
      "        2.14509820e+00, 2.59871952e+01, 1.15765165e+02],\n",
      "       [1.72671512e+06, 1.00451782e+01, 3.75515617e+02, ...,\n",
      "        2.80152274e+00, 1.33788697e+01, 5.36421037e+01],\n",
      "       [9.62147237e+02, 1.65778502e+00, 5.73299929e+01, ...,\n",
      "        1.25387314e+00, 1.78119191e+00, 5.11290843e+00]])>, <tf.Tensor: shape=(32,), dtype=int64, numpy=\n",
      "array([1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(32, 366), dtype=float64, numpy=\n",
      "array([[7.18592921e+03, 3.23607358e-01, 1.15227912e+01, ...,\n",
      "        2.04995645e+00, 1.62166516e+01, 3.82303101e+01],\n",
      "       [9.12712424e+03, 1.04580948e+00, 3.67801059e+01, ...,\n",
      "        3.88369238e-01, 2.20049532e+00, 3.56745787e+00],\n",
      "       [1.25315558e+04, 1.13342114e+00, 5.87944622e+01, ...,\n",
      "        2.61845443e+00, 1.02666002e+01, 4.45751495e+01],\n",
      "       ...,\n",
      "       [2.12264698e+03, 3.11291565e+00, 1.15359026e+02, ...,\n",
      "        5.71402220e+00, 3.76835656e+01, 5.42686890e+02],\n",
      "       [1.85586948e+05, 1.65572124e+01, 3.84852173e+02, ...,\n",
      "        1.44962271e+01, 1.77445667e+02, 2.09004501e+02],\n",
      "       [8.78941527e+02, 6.02803071e-01, 2.30900296e+01, ...,\n",
      "        9.45339151e-01, 9.41596730e+00, 5.15553131e+00]])>, <tf.Tensor: shape=(32,), dtype=int64, numpy=\n",
      "array([0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
      "       0, 0, 0, 1, 0, 1, 0, 1, 0, 0], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(24, 366), dtype=float64, numpy=\n",
      "array([[1.54663830e+03, 1.65483103e-01, 5.76404933e+00, ...,\n",
      "        7.72858758e-01, 3.24130310e+00, 2.52805024e+00],\n",
      "       [3.80854898e+03, 7.81473263e+00, 1.81045302e+02, ...,\n",
      "        5.31596899e+00, 1.48579062e+01, 3.07983349e+00],\n",
      "       [8.43214959e+05, 4.34746927e+05, 2.42866171e+06, ...,\n",
      "        1.19765499e+00, 1.22989117e+00, 4.75348365e-01],\n",
      "       ...,\n",
      "       [8.04276369e+03, 6.61428294e-01, 1.65305390e+01, ...,\n",
      "        4.47688715e+00, 1.01933976e+01, 3.12443757e+00],\n",
      "       [6.03943243e+03, 5.71573790e+00, 3.24474746e+02, ...,\n",
      "        6.91634757e+01, 2.43372745e+01, 7.54745418e+01],\n",
      "       [1.41871284e+04, 3.33627126e+00, 1.71981941e+02, ...,\n",
      "        3.95566637e+01, 4.29158826e+02, 2.53258151e+02]])>, <tf.Tensor: shape=(24,), dtype=int64, numpy=\n",
      "array([0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1,\n",
      "       1, 0], dtype=int64)>)\n"
     ]
    }
   ],
   "source": [
    "for x in val_ds:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 366, 1)]          0         \n",
      "                                                                 \n",
      " conv1d_20 (Conv1D)          (None, 183, 32)           128       \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 183, 32)          128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1d_21 (Conv1D)          (None, 92, 64)            6208      \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 92, 64)           256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1d_22 (Conv1D)          (None, 46, 128)           41088     \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 46, 128)          512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1d_23 (Conv1D)          (None, 23, 256)           164096    \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 23, 256)          1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1d_24 (Conv1D)          (None, 12, 512)           918016    \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 12, 512)          2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv1d_25 (Conv1D)          (None, 6, 1024)           3671040   \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 6, 1024)          4096      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 6, 1024)           0         \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 6144)              0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 4096)              25169920  \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 2048)              8390656   \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 1024)              2098176   \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 128)               131200    \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,598,721\n",
      "Trainable params: 40,594,689\n",
      "Non-trainable params: 4,032\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "15/15 [==============================] - 9s 349ms/step - loss: 35.9717 - accuracy: 0.5312 - val_loss: 25.5114 - val_accuracy: 0.4833\n",
      "Epoch 2/200\n",
      "15/15 [==============================] - 4s 288ms/step - loss: 19.4100 - accuracy: 0.4729 - val_loss: 13.9264 - val_accuracy: 0.4917\n",
      "Epoch 3/200\n",
      "15/15 [==============================] - 4s 289ms/step - loss: 11.0705 - accuracy: 0.4958 - val_loss: 8.5164 - val_accuracy: 0.4500\n",
      "Epoch 4/200\n",
      "15/15 [==============================] - 4s 287ms/step - loss: 7.0968 - accuracy: 0.5021 - val_loss: 5.7686 - val_accuracy: 0.4917\n",
      "Epoch 5/200\n",
      "15/15 [==============================] - 4s 286ms/step - loss: 4.9705 - accuracy: 0.4604 - val_loss: 4.2013 - val_accuracy: 0.4917\n",
      "Epoch 6/200\n",
      "15/15 [==============================] - 4s 288ms/step - loss: 3.7139 - accuracy: 0.5083 - val_loss: 3.2333 - val_accuracy: 0.5167\n",
      "Epoch 7/200\n",
      "15/15 [==============================] - 4s 287ms/step - loss: 2.9158 - accuracy: 0.5146 - val_loss: 2.5973 - val_accuracy: 0.5083\n",
      "Epoch 8/200\n",
      "15/15 [==============================] - 4s 289ms/step - loss: 2.3804 - accuracy: 0.4875 - val_loss: 2.1593 - val_accuracy: 0.5167\n",
      "Epoch 9/200\n",
      "15/15 [==============================] - 4s 281ms/step - loss: 2.0053 - accuracy: 0.5125 - val_loss: 1.8477 - val_accuracy: 0.4333\n",
      "Epoch 10/200\n",
      "15/15 [==============================] - 5s 319ms/step - loss: 1.7343 - accuracy: 0.5000 - val_loss: 1.6178 - val_accuracy: 0.4667\n",
      "Epoch 11/200\n",
      " 7/15 [=============>................] - ETA: 2s - loss: 1.5796 - accuracy: 0.5045"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m'\u001b[39m, optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      6\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_ds, epochs\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(val_ds))\n",
      "File \u001b[1;32mc:\\Users\\fulky\\anaconda3\\envs\\skripsi\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\fulky\\anaconda3\\envs\\skripsi\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\fulky\\anaconda3\\envs\\skripsi\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\fulky\\anaconda3\\envs\\skripsi\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\fulky\\anaconda3\\envs\\skripsi\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\fulky\\anaconda3\\envs\\skripsi\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\fulky\\anaconda3\\envs\\skripsi\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\fulky\\anaconda3\\envs\\skripsi\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\fulky\\anaconda3\\envs\\skripsi\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_ds, epochs=200, validation_data=(val_ds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skripsi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

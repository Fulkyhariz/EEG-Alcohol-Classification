{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn import preprocessing, model_selection\n",
    "import csv\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(directory):\n",
    "    data = pd.DataFrame(columns=['data', 'label'])\n",
    "    for foldername in os.listdir(directory):\n",
    "        folder = os.path.join(directory, foldername)\n",
    "        if os.path.isdir(folder):\n",
    "            files = os.listdir(folder)\n",
    "            for filename in files:\n",
    "                rel_path = os.path.join(directory, foldername, filename)\n",
    "                temp_label = filename.split('.')[0].split('_')[0]\n",
    "                if 'a' in temp_label:\n",
    "                    label ='alcoholic'\n",
    "                else:\n",
    "                    label = 'control'\n",
    "\n",
    "                temp_data = pd.DataFrame(columns=['data', 'label'], index=[0])\n",
    "\n",
    "                rwb = np.load(rel_path)\n",
    "                rwb.astype(np.float64).reshape(-1,1)\n",
    "                # print(rwb)\n",
    "                # with open(rel_path, 'r') as file:\n",
    "                    \n",
    "                #     rwb = list(csv.reader(file, delimiter=\",\"))[0]\n",
    "                #     # scaler = preprocessing.MinMaxScaler()\n",
    "                #     rwb = np.asarray(rwb).astype(np.float64).reshape(-1,1)\n",
    "                #     # print(rwb)\n",
    "                                \n",
    "                temp_data['data'][0] = rwb\n",
    "                temp_data['label'] = label\n",
    "                \n",
    "                # decomp = np.arange(0, 366)\n",
    "                # plt.plot(decomp, df_data)\n",
    "                # plt.xlabel('Dimension Number')\n",
    "                # plt.ylabel('Wavelet Bispectrum Energy')\n",
    "                # plt.show()\n",
    "                data = pd.concat([data, temp_data], ignore_index=True)\n",
    "    label_map = {\"alcoholic\": 1, \"control\": 0}\n",
    "    data['label_map'] = data['label'].map(label_map)\n",
    "    # print(data)      \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(path):\n",
    "    # loading extracted feature & label\n",
    "    x = get_dataset(path)\n",
    "\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "    series_list = [\n",
    "        i for i in x[\"data\"]\n",
    "    ]\n",
    "\n",
    "    # series_list = series_list.reshape(-1, 366, 1)\n",
    "\n",
    "    labels_list = [i for i in x[\"label_map\"]]\n",
    "        \n",
    "    # y = keras.utils.to_categorical(y[0])\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((series_list,labels_list))\n",
    "    dataset = dataset.shuffle(len(labels_list)).batch(32)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = get_batch('../smni_cmi_test_bispectrum_256')\n",
    "for i in test:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "signal = np.load('../smni_cmi_test_bispectrum_256\\co2a0000364\\co2a0000364_48_bispectrum.npy')\n",
    "\n",
    "\n",
    "# Extract the signal values from the DataFrame\n",
    "\n",
    "# Create a time axis for the signal\n",
    "t = range(len(signal))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "# Plot the signal\n",
    "ax.plot(t, signal)\n",
    "ax.set_xlabel('Time (samples)')\n",
    "ax.set_ylabel('Signal amplitude')\n",
    "ax.set_title('Signal plot')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = keras.models.Sequential()\n",
    "\n",
    "    model.add(layers.Input(shape=(915,)))\n",
    "    model.add(layers.Reshape((915, 1)))\n",
    "\n",
    "    model.add(layers.Conv1D(filters=16, kernel_size=4, activation=\"relu\"))\n",
    "    model.add(layers.MaxPooling1D(pool_size=4))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    model.add(layers.Conv1D(filters=8, kernel_size=2, activation=\"relu\"))\n",
    "    model.add(layers.MaxPooling1D(pool_size=4))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    model.add(layers.Dense(512, activation=\"relu\"))\n",
    "\n",
    "    model.add(layers.Dropout(0.5))\n",
    "\n",
    "    model.add(layers.Dense(256, activation=\"relu\"))\n",
    "\n",
    "    model.add(layers.Dropout(0.5))\n",
    "\n",
    "    model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myCallbacks(log_dir):\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "    return tensorboard_callback\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lags = [256, 128, 64, 32, 16, 8, 4, 2]\n",
    "folds = ['train_1', 'test_1', 'train_2', 'test_2']\n",
    "epochs = 100\n",
    "log_dir = 'logs'\n",
    "train_dir = '../smni_cmi_train_bispectrum'\n",
    "test_dir = '../smni_cmi_train_bispectrum'\n",
    "\n",
    "recap = pd.DataFrame(index=lags, columns=folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " reshape_1 (Reshape)         (None, 915, 1)            0         \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 912, 16)           80        \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 228, 16)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 228, 16)          64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 227, 8)            264       \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 56, 8)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 56, 8)            32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 448)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 512)               229888    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 361,913\n",
      "Trainable params: 361,865\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "2/2 [==============================] - 2s 332ms/step - loss: 0.6730 - acc: 0.5938 - val_loss: 0.1214 - val_acc: 1.0000\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.1304 - acc: 1.0000 - val_loss: 0.0466 - val_acc: 1.0000\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.0402 - acc: 1.0000 - val_loss: 0.1294 - val_acc: 1.0000\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.0089 - acc: 1.0000 - val_loss: 0.0796 - val_acc: 1.0000\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0351 - val_acc: 1.0000\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 1.3448e-04 - acc: 1.0000 - val_loss: 0.0820 - val_acc: 1.0000\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 2.0778e-05 - acc: 1.0000 - val_loss: 0.0428 - val_acc: 1.0000\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 6.6704e-05 - acc: 1.0000 - val_loss: 0.0991 - val_acc: 1.0000\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 2.0703e-05 - acc: 1.0000 - val_loss: 0.0407 - val_acc: 1.0000\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 4.6747e-06 - acc: 1.0000 - val_loss: 0.0454 - val_acc: 1.0000\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 4.9947e-07 - acc: 1.0000 - val_loss: 0.0216 - val_acc: 1.0000\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 6.7901e-06 - acc: 1.0000 - val_loss: 0.0324 - val_acc: 1.0000\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 1.2804e-06 - acc: 1.0000 - val_loss: 0.0245 - val_acc: 1.0000\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 6.8791e-07 - acc: 1.0000 - val_loss: 0.0211 - val_acc: 1.0000\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 3.4612e-07 - acc: 1.0000 - val_loss: 0.0128 - val_acc: 1.0000\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 3.1252e-07 - acc: 1.0000 - val_loss: 0.0062 - val_acc: 1.0000\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 9.3741e-08 - acc: 1.0000 - val_loss: 0.0069 - val_acc: 1.0000\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 3.1467e-07 - acc: 1.0000 - val_loss: 0.0144 - val_acc: 1.0000\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.2125e-07 - acc: 1.0000 - val_loss: 0.0089 - val_acc: 1.0000\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 4.9168e-07 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 5.3319e-08 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 1.1739e-07 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 1.2344e-08 - acc: 1.0000 - val_loss: 0.0052 - val_acc: 1.0000\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 1.5348e-08 - acc: 1.0000 - val_loss: 0.0054 - val_acc: 1.0000\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 3.1231e-09 - acc: 1.0000 - val_loss: 5.3784e-04 - val_acc: 1.0000\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 3.6001e-08 - acc: 1.0000 - val_loss: 4.2338e-04 - val_acc: 1.0000\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.2813e-07 - acc: 1.0000 - val_loss: 6.3445e-04 - val_acc: 1.0000\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 2.6978e-08 - acc: 1.0000 - val_loss: 2.8837e-04 - val_acc: 1.0000\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 4.3810e-08 - acc: 1.0000 - val_loss: 8.7935e-04 - val_acc: 1.0000\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.9601e-08 - acc: 1.0000 - val_loss: 1.8074e-04 - val_acc: 1.0000\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 4.2021e-09 - acc: 1.0000 - val_loss: 1.0541e-04 - val_acc: 1.0000\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 4.7207e-07 - acc: 1.0000 - val_loss: 4.7306e-04 - val_acc: 1.0000\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 1.0792e-07 - acc: 1.0000 - val_loss: 2.0219e-04 - val_acc: 1.0000\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 1.1782e-08 - acc: 1.0000 - val_loss: 3.1162e-04 - val_acc: 1.0000\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 4.6855e-08 - acc: 1.0000 - val_loss: 2.4335e-04 - val_acc: 1.0000\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 1.4126e-08 - acc: 1.0000 - val_loss: 9.4015e-05 - val_acc: 1.0000\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 8.0223e-08 - acc: 1.0000 - val_loss: 1.2891e-04 - val_acc: 1.0000\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 1.0641e-07 - acc: 1.0000 - val_loss: 3.9138e-05 - val_acc: 1.0000\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 1.3526e-08 - acc: 1.0000 - val_loss: 1.2342e-04 - val_acc: 1.0000\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 1.2227e-07 - acc: 1.0000 - val_loss: 8.2935e-05 - val_acc: 1.0000\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 2.7095e-08 - acc: 1.0000 - val_loss: 1.2570e-04 - val_acc: 1.0000\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 6.9645e-08 - acc: 1.0000 - val_loss: 1.8462e-05 - val_acc: 1.0000\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 1.0753e-07 - acc: 1.0000 - val_loss: 6.8897e-05 - val_acc: 1.0000\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 2.6241e-08 - acc: 1.0000 - val_loss: 1.2240e-04 - val_acc: 1.0000\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 5.5991e-08 - acc: 1.0000 - val_loss: 6.5075e-05 - val_acc: 1.0000\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 1.2796e-07 - acc: 1.0000 - val_loss: 8.2465e-05 - val_acc: 1.0000\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 2.9345e-07 - acc: 1.0000 - val_loss: 2.3444e-05 - val_acc: 1.0000\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 1.1171e-07 - acc: 1.0000 - val_loss: 5.0428e-05 - val_acc: 1.0000\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 6.6067e-08 - acc: 1.0000 - val_loss: 2.9603e-05 - val_acc: 1.0000\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 5.6514e-08 - acc: 1.0000 - val_loss: 6.8118e-05 - val_acc: 1.0000\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 1.6306e-07 - acc: 1.0000 - val_loss: 2.0653e-05 - val_acc: 1.0000\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 1.3854e-08 - acc: 1.0000 - val_loss: 4.1381e-06 - val_acc: 1.0000\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 2.1836e-07 - acc: 1.0000 - val_loss: 9.9734e-06 - val_acc: 1.0000\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 1.5987e-07 - acc: 1.0000 - val_loss: 1.6142e-06 - val_acc: 1.0000\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 5.7236e-08 - acc: 1.0000 - val_loss: 6.3815e-06 - val_acc: 1.0000\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 2.5455e-07 - acc: 1.0000 - val_loss: 3.8715e-06 - val_acc: 1.0000\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 6.9331e-08 - acc: 1.0000 - val_loss: 3.4674e-06 - val_acc: 1.0000\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 1.7275e-08 - acc: 1.0000 - val_loss: 4.9309e-06 - val_acc: 1.0000\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 2.1795e-08 - acc: 1.0000 - val_loss: 4.8410e-06 - val_acc: 1.0000\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 1.4091e-07 - acc: 1.0000 - val_loss: 2.8505e-06 - val_acc: 1.0000\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 2.7011e-08 - acc: 1.0000 - val_loss: 5.5561e-06 - val_acc: 1.0000\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 2.8639e-08 - acc: 1.0000 - val_loss: 1.1448e-06 - val_acc: 1.0000\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 7.6556e-08 - acc: 1.0000 - val_loss: 8.2768e-06 - val_acc: 1.0000\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 3.2559e-07 - acc: 1.0000 - val_loss: 1.6116e-06 - val_acc: 1.0000\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 2.3652e-08 - acc: 1.0000 - val_loss: 3.7939e-06 - val_acc: 1.0000\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 1.7290e-08 - acc: 1.0000 - val_loss: 2.4943e-06 - val_acc: 1.0000\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 2.9559e-08 - acc: 1.0000 - val_loss: 2.5784e-06 - val_acc: 1.0000\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 1.5580e-08 - acc: 1.0000 - val_loss: 1.9361e-06 - val_acc: 1.0000\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 5.4663e-07 - acc: 1.0000 - val_loss: 4.3982e-07 - val_acc: 1.0000\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 4.2857e-08 - acc: 1.0000 - val_loss: 1.7054e-06 - val_acc: 1.0000\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 2.3729e-07 - acc: 1.0000 - val_loss: 1.7221e-06 - val_acc: 1.0000\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 4.6656e-08 - acc: 1.0000 - val_loss: 2.2684e-06 - val_acc: 1.0000\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 2.6457e-08 - acc: 1.0000 - val_loss: 1.5550e-05 - val_acc: 1.0000\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 1.9877e-07 - acc: 1.0000 - val_loss: 1.7166e-06 - val_acc: 1.0000\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 1.3411e-08 - acc: 1.0000 - val_loss: 8.7212e-07 - val_acc: 1.0000\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 6.6003e-09 - acc: 1.0000 - val_loss: 1.7389e-06 - val_acc: 1.0000\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 1.3819e-08 - acc: 1.0000 - val_loss: 1.7134e-06 - val_acc: 1.0000\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 1.4467e-09 - acc: 1.0000 - val_loss: 1.0698e-05 - val_acc: 1.0000\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 7.6484e-10 - acc: 1.0000 - val_loss: 7.6573e-07 - val_acc: 1.0000\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 5.5561e-08 - acc: 1.0000 - val_loss: 1.8779e-06 - val_acc: 1.0000\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 1.8776e-07 - acc: 1.0000 - val_loss: 6.3694e-07 - val_acc: 1.0000\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 3.3549e-07 - acc: 1.0000 - val_loss: 1.1950e-06 - val_acc: 1.0000\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 1.4358e-07 - acc: 1.0000 - val_loss: 9.5373e-07 - val_acc: 1.0000\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 3.5311e-08 - acc: 1.0000 - val_loss: 8.3105e-06 - val_acc: 1.0000\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 1.3858e-07 - acc: 1.0000 - val_loss: 2.6683e-07 - val_acc: 1.0000\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 2.3231e-08 - acc: 1.0000 - val_loss: 3.5387e-07 - val_acc: 1.0000\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 1.8199e-08 - acc: 1.0000 - val_loss: 6.5073e-07 - val_acc: 1.0000\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 1.0786e-07 - acc: 1.0000 - val_loss: 8.7344e-07 - val_acc: 1.0000\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 1.2658e-07 - acc: 1.0000 - val_loss: 6.2736e-06 - val_acc: 1.0000\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 2.4179e-08 - acc: 1.0000 - val_loss: 1.3273e-06 - val_acc: 1.0000\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.0660e-10 - acc: 1.0000 - val_loss: 4.7602e-07 - val_acc: 1.0000\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 3.6168e-08 - acc: 1.0000 - val_loss: 5.9814e-06 - val_acc: 1.0000\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 7.3457e-08 - acc: 1.0000 - val_loss: 1.2003e-06 - val_acc: 1.0000\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 1.4176e-07 - acc: 1.0000 - val_loss: 8.1287e-07 - val_acc: 1.0000\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 5.1563e-08 - acc: 1.0000 - val_loss: 5.5151e-07 - val_acc: 1.0000\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 6.9095e-08 - acc: 1.0000 - val_loss: 2.2594e-07 - val_acc: 1.0000\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 1.0631e-08 - acc: 1.0000 - val_loss: 5.3281e-07 - val_acc: 1.0000\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 9.6493e-09 - acc: 1.0000 - val_loss: 1.1594e-06 - val_acc: 1.0000\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 1.9839e-08 - acc: 1.0000 - val_loss: 5.2201e-07 - val_acc: 1.0000\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 4.1829e-08 - acc: 1.0000 - val_loss: 3.8504e-06 - val_acc: 1.0000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.1055e-06 - acc: 1.0000\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " reshape_2 (Reshape)         (None, 915, 1)            0         \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 912, 16)           80        \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPooling  (None, 228, 16)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 228, 16)          64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 227, 8)            264       \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPooling  (None, 56, 8)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 56, 8)            32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 448)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 512)               229888    \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 361,913\n",
      "Trainable params: 361,865\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "2/2 [==============================] - 2s 262ms/step - loss: 0.4306 - acc: 0.8281 - val_loss: 0.0891 - val_acc: 1.0000\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.1357 - acc: 1.0000 - val_loss: 0.0840 - val_acc: 1.0000\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.0171 - acc: 1.0000 - val_loss: 0.0431 - val_acc: 1.0000\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0519 - val_acc: 1.0000\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 2.7206e-04 - acc: 1.0000 - val_loss: 0.0808 - val_acc: 1.0000\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 8.9849e-05 - acc: 1.0000 - val_loss: 0.0717 - val_acc: 1.0000\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 5.4978e-06 - acc: 1.0000 - val_loss: 0.1165 - val_acc: 1.0000\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.6014e-05 - acc: 1.0000 - val_loss: 0.0507 - val_acc: 1.0000\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 3.7345e-07 - acc: 1.0000 - val_loss: 0.0828 - val_acc: 1.0000\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 1.3736e-06 - acc: 1.0000 - val_loss: 0.0737 - val_acc: 1.0000\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 3.4380e-07 - acc: 1.0000 - val_loss: 0.0602 - val_acc: 1.0000\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 8.1098e-07 - acc: 1.0000 - val_loss: 0.0489 - val_acc: 1.0000\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 1.1699e-07 - acc: 1.0000 - val_loss: 0.0542 - val_acc: 1.0000\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 1.2306e-09 - acc: 1.0000 - val_loss: 0.0464 - val_acc: 1.0000\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 1.3339e-07 - acc: 1.0000 - val_loss: 0.0373 - val_acc: 1.0000\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 7.4992e-08 - acc: 1.0000 - val_loss: 0.0376 - val_acc: 1.0000\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 1.4621e-09 - acc: 1.0000 - val_loss: 0.0234 - val_acc: 1.0000\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 1.3281e-08 - acc: 1.0000 - val_loss: 0.0246 - val_acc: 1.0000\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 7.7341e-09 - acc: 1.0000 - val_loss: 0.0121 - val_acc: 1.0000\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 3.6293e-08 - acc: 1.0000 - val_loss: 0.0083 - val_acc: 1.0000\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 1.5727e-08 - acc: 1.0000 - val_loss: 0.0108 - val_acc: 1.0000\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 2.0316e-08 - acc: 1.0000 - val_loss: 0.0078 - val_acc: 1.0000\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 7.2884e-09 - acc: 1.0000 - val_loss: 0.0062 - val_acc: 1.0000\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 1.8513e-08 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 5.6698e-09 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 7.6010e-08 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 2.1293e-09 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 5.4940e-08 - acc: 1.0000 - val_loss: 0.0050 - val_acc: 1.0000\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.3035e-08 - acc: 1.0000 - val_loss: 5.7662e-04 - val_acc: 1.0000\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 3.9915e-08 - acc: 1.0000 - val_loss: 6.6229e-04 - val_acc: 1.0000\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 3.3023e-09 - acc: 1.0000 - val_loss: 2.1340e-04 - val_acc: 1.0000\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 1.8826e-08 - acc: 1.0000 - val_loss: 8.0968e-04 - val_acc: 1.0000\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 3.9111e-10 - acc: 1.0000 - val_loss: 4.8268e-04 - val_acc: 1.0000\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 8.0018e-10 - acc: 1.0000 - val_loss: 9.6313e-05 - val_acc: 1.0000\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 4.4000e-08 - acc: 1.0000 - val_loss: 1.8738e-04 - val_acc: 1.0000\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 1.1062e-08 - acc: 1.0000 - val_loss: 4.5425e-04 - val_acc: 1.0000\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 8.5550e-10 - acc: 1.0000 - val_loss: 3.2435e-04 - val_acc: 1.0000\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 1.1946e-08 - acc: 1.0000 - val_loss: 1.7488e-04 - val_acc: 1.0000\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 5.6954e-09 - acc: 1.0000 - val_loss: 1.1850e-04 - val_acc: 1.0000\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 3.0111e-09 - acc: 1.0000 - val_loss: 1.7519e-04 - val_acc: 1.0000\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 1.3754e-10 - acc: 1.0000 - val_loss: 1.9159e-04 - val_acc: 1.0000\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 1.1678e-08 - acc: 1.0000 - val_loss: 9.6166e-05 - val_acc: 1.0000\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 1.9034e-08 - acc: 1.0000 - val_loss: 1.3568e-04 - val_acc: 1.0000\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 4.7663e-09 - acc: 1.0000 - val_loss: 1.3449e-04 - val_acc: 1.0000\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 4.2449e-09 - acc: 1.0000 - val_loss: 1.9777e-05 - val_acc: 1.0000\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 2.1891e-08 - acc: 1.0000 - val_loss: 3.2481e-05 - val_acc: 1.0000\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 7.5059e-08 - acc: 1.0000 - val_loss: 1.3033e-05 - val_acc: 1.0000\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 3.9911e-09 - acc: 1.0000 - val_loss: 3.0810e-05 - val_acc: 1.0000\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 2.8586e-09 - acc: 1.0000 - val_loss: 1.8691e-05 - val_acc: 1.0000\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 3.2472e-08 - acc: 1.0000 - val_loss: 4.7308e-06 - val_acc: 1.0000\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 7.7688e-09 - acc: 1.0000 - val_loss: 5.1864e-06 - val_acc: 1.0000\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 7.7077e-09 - acc: 1.0000 - val_loss: 4.7842e-05 - val_acc: 1.0000\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 4.7470e-09 - acc: 1.0000 - val_loss: 2.7513e-06 - val_acc: 1.0000\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 1.0386e-08 - acc: 1.0000 - val_loss: 9.1256e-06 - val_acc: 1.0000\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 2.4384e-09 - acc: 1.0000 - val_loss: 1.2704e-05 - val_acc: 1.0000\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 5.5043e-09 - acc: 1.0000 - val_loss: 7.4614e-06 - val_acc: 1.0000\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 1.5033e-08 - acc: 1.0000 - val_loss: 2.1293e-06 - val_acc: 1.0000\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 2.5061e-09 - acc: 1.0000 - val_loss: 1.1121e-05 - val_acc: 1.0000\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 2.8899e-09 - acc: 1.0000 - val_loss: 1.3189e-05 - val_acc: 1.0000\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 2.0445e-09 - acc: 1.0000 - val_loss: 4.3862e-06 - val_acc: 1.0000\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 2.0503e-08 - acc: 1.0000 - val_loss: 8.6506e-06 - val_acc: 1.0000\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.9767e-08 - acc: 1.0000 - val_loss: 1.9214e-05 - val_acc: 1.0000\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 2.6768e-11 - acc: 1.0000 - val_loss: 2.0019e-06 - val_acc: 1.0000\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 5.8127e-08 - acc: 1.0000 - val_loss: 1.2075e-06 - val_acc: 1.0000\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 3.0634e-09 - acc: 1.0000 - val_loss: 3.6468e-07 - val_acc: 1.0000\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 6.0495e-09 - acc: 1.0000 - val_loss: 3.1163e-07 - val_acc: 1.0000\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 2.8144e-11 - acc: 1.0000 - val_loss: 3.2776e-06 - val_acc: 1.0000\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 4.6401e-09 - acc: 1.0000 - val_loss: 3.5915e-07 - val_acc: 1.0000\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 4.0591e-09 - acc: 1.0000 - val_loss: 2.8784e-06 - val_acc: 1.0000\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 9.3912e-09 - acc: 1.0000 - val_loss: 1.2418e-06 - val_acc: 1.0000\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 7.5382e-08 - acc: 1.0000 - val_loss: 1.8473e-06 - val_acc: 1.0000\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 1.3472e-08 - acc: 1.0000 - val_loss: 6.0702e-07 - val_acc: 1.0000\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 3.2730e-09 - acc: 1.0000 - val_loss: 3.4333e-07 - val_acc: 1.0000\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 3.5776e-10 - acc: 1.0000 - val_loss: 9.9319e-08 - val_acc: 1.0000\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 5.4948e-09 - acc: 1.0000 - val_loss: 9.2431e-07 - val_acc: 1.0000\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 5.4511e-09 - acc: 1.0000 - val_loss: 1.6345e-06 - val_acc: 1.0000\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 1.7469e-08 - acc: 1.0000 - val_loss: 3.8953e-07 - val_acc: 1.0000\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 1.4458e-09 - acc: 1.0000 - val_loss: 1.5683e-07 - val_acc: 1.0000\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 2.5941e-08 - acc: 1.0000 - val_loss: 3.4962e-07 - val_acc: 1.0000\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 3.9806e-09 - acc: 1.0000 - val_loss: 6.5191e-07 - val_acc: 1.0000\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 2.1587e-12 - acc: 1.0000 - val_loss: 2.2782e-06 - val_acc: 1.0000\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 8.2432e-10 - acc: 1.0000 - val_loss: 1.6111e-07 - val_acc: 1.0000\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 9.2678e-09 - acc: 1.0000 - val_loss: 5.6360e-08 - val_acc: 1.0000\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 4.4785e-09 - acc: 1.0000 - val_loss: 1.2264e-07 - val_acc: 1.0000\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 3.5380e-09 - acc: 1.0000 - val_loss: 1.1123e-06 - val_acc: 1.0000\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 4.0370e-09 - acc: 1.0000 - val_loss: 1.1259e-07 - val_acc: 1.0000\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 2.9235e-09 - acc: 1.0000 - val_loss: 9.1618e-08 - val_acc: 1.0000\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 8.7867e-10 - acc: 1.0000 - val_loss: 1.4350e-08 - val_acc: 1.0000\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 2.6115e-08 - acc: 1.0000 - val_loss: 7.7010e-08 - val_acc: 1.0000\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 4.1601e-09 - acc: 1.0000 - val_loss: 2.2865e-08 - val_acc: 1.0000\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 1.7341e-10 - acc: 1.0000 - val_loss: 2.9995e-07 - val_acc: 1.0000\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 1.1115e-08 - acc: 1.0000 - val_loss: 7.5354e-08 - val_acc: 1.0000\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 5.6255e-09 - acc: 1.0000 - val_loss: 3.8228e-07 - val_acc: 1.0000\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 5.1379e-10 - acc: 1.0000 - val_loss: 3.2001e-07 - val_acc: 1.0000\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 1.9140e-07 - acc: 1.0000 - val_loss: 3.7377e-07 - val_acc: 1.0000\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 4.7418e-08 - acc: 1.0000 - val_loss: 1.2765e-08 - val_acc: 1.0000\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 5.3246e-09 - acc: 1.0000 - val_loss: 1.1447e-08 - val_acc: 1.0000\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 1.8860e-09 - acc: 1.0000 - val_loss: 5.2902e-08 - val_acc: 1.0000\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 4.7043e-12 - acc: 1.0000 - val_loss: 9.2364e-08 - val_acc: 1.0000\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 3.6059e-09 - acc: 1.0000 - val_loss: 1.6395e-07 - val_acc: 1.0000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 6.0052e-08 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "for fold in range(1,3):\n",
    "    for lag in [256]:\n",
    "        if fold == 2:\n",
    "            train_dir, test_dir = test_dir, train_dir\n",
    "        \n",
    "        train_temp_dir = train_dir + '_' + str(lag)\n",
    "        test_temp_dir = test_dir + '_' + str(lag)\n",
    "\n",
    "        train = get_batch('../smni_cmi_test_bispectrum_256')\n",
    "        test_ds = get_batch('../smni_cmi_test_bispectrum_256')\n",
    "\n",
    "        train_size = int(len(list(train.as_numpy_iterator()))*0.8)\n",
    "        train_ds = train.take(train_size)\n",
    "        val_ds = train.skip(train_size)\n",
    "\n",
    "        log_path = os.path.join(log_dir, str(fold), str(lag))\n",
    "\n",
    "        model = create_model()\n",
    "        model.summary()\n",
    "\n",
    "        model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(), metrics=['acc'])\n",
    "\n",
    "        history = model.fit(train_ds, epochs=epochs, validation_data=(val_ds), callbacks = myCallbacks(log_path))\n",
    "        results = model.evaluate(test_ds, callbacks = myCallbacks(log_path))\n",
    "\n",
    "        recap.loc[lag, 'train'+ '_' + str(fold)] = history.history['acc'][-1]\n",
    "        recap.loc[lag, 'test'+ '_' + str(fold)] = results[1]\n",
    "\n",
    "        model.save(os.path.join(log_path,'model.h5'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recap.to_csv('../Logs/Recap/recap.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! tensorboard --logdir logs --port=8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skripsi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

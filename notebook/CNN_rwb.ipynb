{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn import preprocessing, model_selection\n",
    "import csv\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(directory):\n",
    "    data = pd.DataFrame(columns=['data', 'label'])\n",
    "    for foldername in os.listdir(directory):\n",
    "        folder = os.path.join(directory, foldername)\n",
    "        if os.path.isdir(folder):\n",
    "            files = os.listdir(folder)\n",
    "            for filename in files:\n",
    "                rel_path = os.path.join(directory, foldername, filename)\n",
    "                temp_label = filename.split('.')[0].split('_')[0]\n",
    "                if 'a' in temp_label:\n",
    "                    label ='alcoholic'\n",
    "                else:\n",
    "                    label = 'control'\n",
    "\n",
    "                temp_data = pd.DataFrame(columns=['data', 'label'], index=[0])\n",
    "\n",
    "                rwb = np.load(rel_path)\n",
    "                rwb.astype(np.float64).reshape(-1,1)\n",
    "                # with open(rel_path, 'r') as file:\n",
    "                    \n",
    "                #     rwb = list(csv.reader(file, delimiter=\",\"))[0]\n",
    "                #     # scaler = preprocessing.MinMaxScaler()\n",
    "                #     rwb = np.asarray(rwb).astype(np.float64).reshape(-1,1)\n",
    "                #     # print(rwb)\n",
    "                                \n",
    "                temp_data['data'][0] = rwb\n",
    "                temp_data['label'] = label\n",
    "                \n",
    "                # decomp = np.arange(0, 366)\n",
    "                # plt.plot(decomp, df_data)\n",
    "                # plt.xlabel('Dimension Number')\n",
    "                # plt.ylabel('Wavelet Bispectrum Energy')\n",
    "                # plt.show()\n",
    "                data = pd.concat([data, temp_data], ignore_index=True)\n",
    "    label_map = {\"alcoholic\": 1, \"control\": 0}\n",
    "    data['label_map'] = data['label'].map(label_map)      \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(path):\n",
    "    # loading extracted feature & label\n",
    "    x = get_dataset(path)\n",
    "\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "    series_list = [\n",
    "        i for i in x[\"data\"]\n",
    "    ]\n",
    "\n",
    "    # series_list = series_list.reshape(-1, 366, 1)\n",
    "\n",
    "    labels_list = [i for i in x[\"label_map\"]]\n",
    "        \n",
    "    # y = keras.utils.to_categorical(y[0])\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((series_list,labels_list))\n",
    "    dataset = dataset.shuffle(len(labels_list)).batch(32)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = get_batch('../Feature/Train/smni_cmi_train_feature_256')\n",
    "for i in test:\n",
    "    print(i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "bis_2 = np.load('./Test Bispec/2.npy')\n",
    "bis_4 = np.load('./Test Bispec/4.npy')\n",
    "bis_8 = np.load('./Test Bispec/8.npy')\n",
    "bis_16 = np.load('./Test Bispec/16.npy')\n",
    "bis_32 = np.load('./Test Bispec/32.npy')\n",
    "bis_64 = np.load('./Test Bispec/64.npy')\n",
    "bis_128 = np.load('./Test Bispec/128.npy')\n",
    "bis_256 = np.load('./Test Bispec/256.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rwb_256 = np.load('../Feature\\Train\\smni_cmi_train_feature_256\\co2a0000364\\co2a0000364_31_feature.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(np.isnan(bis_256).any()):\n",
    "    print(\"The Array contain NaN values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "signal = bis_\n",
    "print((bis_256 == bis_64).all())\n",
    "# Extract the signal values from the DataFrame\n",
    "\n",
    "# Create a time axis for the signal\n",
    "t = range(len(signal))\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(t, signal, color = 'k', linewidth=1)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = keras.models.Sequential()\n",
    "\n",
    "    model.add(layers.Input(shape=(366,)))\n",
    "    model.add(layers.Reshape((366, 1)))\n",
    "\n",
    "    model.add(layers.Conv1D(filters=16, kernel_size=4, activation=\"relu\"))\n",
    "    model.add(layers.MaxPooling1D(pool_size=4))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    model.add(layers.Conv1D(filters=8, kernel_size=2, activation=\"relu\"))\n",
    "    model.add(layers.MaxPooling1D(pool_size=4))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    model.add(layers.Dense(512, activation=\"relu\"))\n",
    "\n",
    "    model.add(layers.Dropout(0.5))\n",
    "\n",
    "    model.add(layers.Dense(256, activation=\"relu\"))\n",
    "\n",
    "    model.add(layers.Dropout(0.5))\n",
    "\n",
    "    model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myCallbacks(log_dir):\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='acc',\n",
    "    patience=50,\n",
    "    mode='max')\n",
    "    model_path = os.path.join(log_dir,'best_model.h5')\n",
    "    mc = tf.keras.callbacks.ModelCheckpoint(model_path, monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "    return [tensorboard_callback, early_stopping, mc]\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lags = [256, 128, 64, 32, 16, 8, 4, 2]\n",
    "folds = ['train_1', 'test_1', 'epoch_1', 'train_2', 'test_2', 'epoch_2']\n",
    "time_measured = ['Wall_Time_1', 'CPU_Time_1', 'Wall_Time_2', 'CPU_Time_2']\n",
    "epochs = 2000\n",
    "log_dir = 'logs'\n",
    "train_dir = '../Feature/Train/smni_cmi_train_feature'\n",
    "test_dir = '../Feature/Train/smni_cmi_train_feature'\n",
    "\n",
    "recap = pd.DataFrame(index=lags, columns=folds)\n",
    "training_time = pd.DataFrame(index=lags, columns=time_measured)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold in range(1,3):\n",
    "    for lag in [256]:\n",
    "        if fold == 2:\n",
    "            train_dir, test_dir = test_dir, train_dir\n",
    "        \n",
    "        train_temp_dir = train_dir + '_' + str(lag)\n",
    "        test_temp_dir = test_dir + '_' + str(lag)\n",
    "\n",
    "        train = get_batch(train_temp_dir)\n",
    "        test_ds = get_batch(test_temp_dir)\n",
    "\n",
    "        train_size = int(len(list(train.as_numpy_iterator()))*0.8)\n",
    "        train_ds = train.take(train_size)\n",
    "        val_ds = train.skip(train_size)\n",
    "\n",
    "        log_path = os.path.join(log_dir, str(fold), str(lag))\n",
    "\n",
    "        model = create_model()\n",
    "        model.summary()\n",
    "\n",
    "        model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(), metrics=['acc'])\n",
    "\n",
    "        cpu_start = time.process_time()\n",
    "        wt_start = time.time()\n",
    "\n",
    "        history = model.fit(train_ds, epochs=epochs, validation_data=(val_ds), callbacks = myCallbacks(log_path))\n",
    "\n",
    "        wt_end = time.time()\n",
    "        cpu_end = time.process_time()\n",
    "        wall_time = wt_end - wt_start\n",
    "        cpu_time = cpu_end - cpu_start\n",
    "        training_time.loc[lag, 'CPU_Time'+ '_' + str(fold)] = cpu_time\n",
    "        training_time.loc[lag, 'Wall_Time'+ '_' + str(fold)] = wall_time\n",
    "\n",
    "        results = model.evaluate(test_ds, callbacks = myCallbacks(log_path))\n",
    "\n",
    "        recap.loc[lag, 'train'+ '_' + str(fold)] = history.history['acc'][-1]\n",
    "        recap.loc[lag, 'test'+ '_' + str(fold)] = results[1]\n",
    "        recap.loc[lag, 'epoch'+ '_' + str(fold)] = len(history.history['acc'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recap.to_csv('../Logs/Recap/recap.csv')\n",
    "training_time.to_csv('../Logs/Recap/training_time.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "! tensorboard --logdir logs --port=8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skripsi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fulky\\anaconda3\\envs\\skripsi\\lib\\site-packages\\stingray\\utils.py:25: UserWarning: pyfftw not installed. Using standard scipy fft\n",
      "  warnings.warn(\"pyfftw not installed. Using standard scipy fft\")\n",
      "c:\\Users\\fulky\\anaconda3\\envs\\skripsi\\lib\\site-packages\\stingray\\utils.py:40: UserWarning: Numba not installed. Faking it\n",
      "  warnings.warn(\"Numba not installed. Faking it\")\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary library\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pywt\n",
    "import pandas as pd\n",
    "import os\n",
    "from scipy import signal\n",
    "from stingray import lightcurve\n",
    "import sys\n",
    "from stingray import Bispectrum\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Menghitung Matriks Cumulant orde ke-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcCumulantOrde3(df_data, t, lag):\n",
    "    # Compute the bispectrum of the signal\n",
    "    lc = lightcurve.Lightcurve(t,df_data.T)\n",
    "    bs = Bispectrum(lc, maxlag=lag)\n",
    "\n",
    "    # Plot the bispectrum using contour plots\n",
    "    # plt.contour(bs.freq, bs.freq, bs.bispec_mag)\n",
    "    # plt.xlabel('f1')\n",
    "    # plt.ylabel('f2')\n",
    "    # plt.show()\n",
    "\n",
    "    # # Plot the bispectrum using mesh plots\n",
    "    # fig = plt.figure()\n",
    "    # ax = fig.add_subplot(111, projection='3d')\n",
    "    # X, Y = np.meshgrid(bs.freq, bs.freq)\n",
    "    # ax.plot_surface(X, Y, bs.bispec_mag)\n",
    "    # ax.set_xlabel('f1')\n",
    "    # ax.set_ylabel('f2')\n",
    "    # ax.set_zlabel('Bispectrum')\n",
    "    # plt.show()\n",
    "\n",
    "    return bs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Melakukan dekomposisi wavelet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcWaveletDec(bs):\n",
    "    # Select wavelet and decomposition level\n",
    "    wavelet = 'db4'\n",
    "    level = 5\n",
    "\n",
    "    # Deecompose signal\n",
    "    coeffs = pywt.wavedec(bs.cum3, wavelet, level=level)\n",
    "    \n",
    "    # # Visualize\n",
    "    # approximations = []\n",
    "    # details = []\n",
    "    # for i in range(level):\n",
    "    #     approximations.append(coeffs[i])\n",
    "    #     details.append(coeffs[level - i])\n",
    "\n",
    "    # fig, axs = plt.subplots(len(coeffs), sharex=True)\n",
    "    # for i, c in enumerate(coeffs):\n",
    "    #     axs[i].plot(c)\n",
    "    #     axs[i].set_ylabel(f'Level {i}')\n",
    "    # plt.show()\n",
    "    return coeffs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Menghitung energi relatif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcRelativeEnergy(coeffs, df_data):\n",
    "    # Calculate relative wavelet energy\n",
    "    energies = []\n",
    "    for c in coeffs:\n",
    "        energies.append(np.sum(np.square(c)))\n",
    "\n",
    "    decomp = ['A5', 'D1', 'D2', 'D3', 'D4', 'D5']\n",
    "\n",
    "    temp = energies\n",
    "    energies[1:6] = energies[-1:-6:-1]\n",
    "\n",
    "    total_energy = np.sum(np.square(df_data.T))\n",
    "    relative_energies = [e / total_energy for e in energies]\n",
    "\n",
    "    # plt.plot(decomp, energies)\n",
    "    # plt.xlabel('Dimension Number')\n",
    "    # plt.ylabel('Wavelet Bispectrum Energy')\n",
    "    # plt.show()\n",
    "\n",
    "    # plt.plot(decomp, relative_energies)\n",
    "    # plt.xlabel('Dimension Number')\n",
    "    # plt.ylabel('Relative Wavelet Bispectrum Energy')\n",
    "    # plt.show()\n",
    "\n",
    "    return energies, relative_energies"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persiapan data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sampling frequency\n",
    "fs = 256\n",
    "t = np.arange(0, 1, 1/fs)\n",
    "\n",
    "def get_csv_EEG(filename):\n",
    "    # Load data from CSV\n",
    "    data = np.loadtxt(filename, delimiter=\",\", skiprows=1, usecols=range(3,259))\n",
    "    channel_name = np.loadtxt(filename, delimiter=\",\", skiprows=1, usecols=1, dtype='str', encoding='utf-8')\n",
    "    \n",
    "    df_data = pd.DataFrame(data.T, columns=channel_name)\n",
    "\n",
    "    df_data = df_data.drop(columns=['X', 'Y', 'nd'])\n",
    "\n",
    "    return df_data, df_data.columns\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perhitungan RWB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(directory, lag):\n",
    "    for foldername in os.listdir(directory):\n",
    "        folder = os.path.join(directory, foldername)\n",
    "        if os.path.isdir(folder):\n",
    "            des_dir = os.path.join(directory.replace('CSV', 'FEATURE')+\"_\" + str(lag),foldername).lower()\n",
    "            files = os.listdir(folder)\n",
    "            for filename in files:\n",
    "                rel_path = os.path.join(directory, foldername, filename)\n",
    "                if 'metadata' in filename.lower():\n",
    "                    continue\n",
    "                trial_number = filename.split('.')[0].split('_')[1]\n",
    "                df_data, channel_name = get_csv_EEG(rel_path)\n",
    "                RWB = []\n",
    "                for channel in channel_name:\n",
    "                    energies, relative_energies = calcRelativeEnergy(calcWaveletDec(calcCumulantOrde3(df_data[channel], t, lag)), df_data[channel])\n",
    "                    RWB = np.append(RWB, relative_energies)\n",
    "                des_file = foldername+'_'+ str(trial_number) + '_feature' +'.csv'\n",
    "                if not os.path.exists(des_dir):\n",
    "                    os.makedirs(des_dir)\n",
    "                des_path = os.path.join(des_dir, des_file)\n",
    "                np.savetxt(des_path, RWB.T, delimiter =\", \", fmt ='% s')\n",
    "                # pd.DataFrame(RWB.T).to_csv(des_path, index=False)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m extract_feature(\u001b[39m'\u001b[39;49m\u001b[39m../SMNI_CMI_TEST_CSV\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m256\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[18], line 12\u001b[0m, in \u001b[0;36mextract_feature\u001b[1;34m(directory, lag)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m     11\u001b[0m trial_number \u001b[39m=\u001b[39m filename\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m1\u001b[39m]\n\u001b[1;32m---> 12\u001b[0m df_data, channel_name \u001b[39m=\u001b[39m get_csv_EEG(rel_path)\n\u001b[0;32m     13\u001b[0m RWB \u001b[39m=\u001b[39m []\n\u001b[0;32m     14\u001b[0m \u001b[39mfor\u001b[39;00m channel \u001b[39min\u001b[39;00m channel_name:\n",
      "Cell \u001b[1;32mIn[5], line 8\u001b[0m, in \u001b[0;36mget_csv_EEG\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_csv_EEG\u001b[39m(filename):\n\u001b[0;32m      6\u001b[0m     \u001b[39m# Load data from CSV\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mloadtxt(filename, delimiter\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m, skiprows\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, usecols\u001b[39m=\u001b[39m\u001b[39mrange\u001b[39m(\u001b[39m3\u001b[39m,\u001b[39m259\u001b[39m))\n\u001b[1;32m----> 8\u001b[0m     channel_name \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mloadtxt(filename, delimiter\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m,\u001b[39;49m\u001b[39m\"\u001b[39;49m, skiprows\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, usecols\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, dtype\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mstr\u001b[39;49m\u001b[39m'\u001b[39;49m, encoding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     10\u001b[0m     df_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(data\u001b[39m.\u001b[39mT, columns\u001b[39m=\u001b[39mchannel_name)\n\u001b[0;32m     12\u001b[0m     df_data \u001b[39m=\u001b[39m df_data\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mX\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mY\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mnd\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\fulky\\anaconda3\\envs\\skripsi\\lib\\site-packages\\numpy\\lib\\npyio.py:1338\u001b[0m, in \u001b[0;36mloadtxt\u001b[1;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, quotechar, like)\u001b[0m\n\u001b[0;32m   1335\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(delimiter, \u001b[39mbytes\u001b[39m):\n\u001b[0;32m   1336\u001b[0m     delimiter \u001b[39m=\u001b[39m delimiter\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39mlatin1\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m-> 1338\u001b[0m arr \u001b[39m=\u001b[39m _read(fname, dtype\u001b[39m=\u001b[39;49mdtype, comment\u001b[39m=\u001b[39;49mcomment, delimiter\u001b[39m=\u001b[39;49mdelimiter,\n\u001b[0;32m   1339\u001b[0m             converters\u001b[39m=\u001b[39;49mconverters, skiplines\u001b[39m=\u001b[39;49mskiprows, usecols\u001b[39m=\u001b[39;49musecols,\n\u001b[0;32m   1340\u001b[0m             unpack\u001b[39m=\u001b[39;49munpack, ndmin\u001b[39m=\u001b[39;49mndmin, encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[0;32m   1341\u001b[0m             max_rows\u001b[39m=\u001b[39;49mmax_rows, quote\u001b[39m=\u001b[39;49mquotechar)\n\u001b[0;32m   1343\u001b[0m \u001b[39mreturn\u001b[39;00m arr\n",
      "File \u001b[1;32mc:\\Users\\fulky\\anaconda3\\envs\\skripsi\\lib\\site-packages\\numpy\\lib\\npyio.py:1026\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(fname, delimiter, comment, quote, imaginary_unit, usecols, skiplines, max_rows, converters, ndmin, unpack, dtype, encoding)\u001b[0m\n\u001b[0;32m   1023\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1024\u001b[0m     chunk_size \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(_loadtxt_chunksize, max_rows)\n\u001b[1;32m-> 1026\u001b[0m next_arr \u001b[39m=\u001b[39m _load_from_filelike(\n\u001b[0;32m   1027\u001b[0m     data, delimiter\u001b[39m=\u001b[39;49mdelimiter, comment\u001b[39m=\u001b[39;49mcomment, quote\u001b[39m=\u001b[39;49mquote,\n\u001b[0;32m   1028\u001b[0m     imaginary_unit\u001b[39m=\u001b[39;49mimaginary_unit,\n\u001b[0;32m   1029\u001b[0m     usecols\u001b[39m=\u001b[39;49musecols, skiplines\u001b[39m=\u001b[39;49mskiplines, max_rows\u001b[39m=\u001b[39;49mmax_rows,\n\u001b[0;32m   1030\u001b[0m     converters\u001b[39m=\u001b[39;49mconverters, dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   1031\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding, filelike\u001b[39m=\u001b[39;49mfilelike,\n\u001b[0;32m   1032\u001b[0m     byte_converters\u001b[39m=\u001b[39;49mbyte_converters,\n\u001b[0;32m   1033\u001b[0m     c_byte_converters\u001b[39m=\u001b[39;49mc_byte_converters)\n\u001b[0;32m   1034\u001b[0m \u001b[39m# Cast here already.  We hope that this is better even for\u001b[39;00m\n\u001b[0;32m   1035\u001b[0m \u001b[39m# large files because the storage is more compact.  It could\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[39m# be adapted (in principle the concatenate could cast).\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m chunks\u001b[39m.\u001b[39mappend(next_arr\u001b[39m.\u001b[39mastype(read_dtype_via_object_chunks))\n",
      "File \u001b[1;32mc:\\Users\\fulky\\anaconda3\\envs\\skripsi\\lib\\codecs.py:319\u001b[0m, in \u001b[0;36mBufferedIncrementalDecoder.decode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_buffer_decode\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, errors, final):\n\u001b[0;32m    315\u001b[0m     \u001b[39m# Overwrite this method in subclasses: It must decode input\u001b[39;00m\n\u001b[0;32m    316\u001b[0m     \u001b[39m# and return an (output, length consumed) tuple\u001b[39;00m\n\u001b[0;32m    317\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m\n\u001b[1;32m--> 319\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    320\u001b[0m     \u001b[39m# decode input (taking the buffer into account)\u001b[39;00m\n\u001b[0;32m    321\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer \u001b[39m+\u001b[39m \u001b[39minput\u001b[39m\n\u001b[0;32m    322\u001b[0m     (result, consumed) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buffer_decode(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39merrors, final)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "extract_feature('../SMNI_CMI_TEST_CSV', 256)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skripsi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7899ebb7610f36207965d38f68f9fcf69ead4646d08358e8b81fddd5bb8ec13e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

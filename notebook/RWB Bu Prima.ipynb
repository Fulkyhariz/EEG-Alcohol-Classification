{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fulky\\anaconda3\\envs\\skripsi\\lib\\site-packages\\stingray\\utils.py:25: UserWarning: pyfftw not installed. Using standard scipy fft\n",
      "  warnings.warn(\"pyfftw not installed. Using standard scipy fft\")\n",
      "c:\\Users\\fulky\\anaconda3\\envs\\skripsi\\lib\\site-packages\\stingray\\utils.py:40: UserWarning: Numba not installed. Faking it\n",
      "  warnings.warn(\"Numba not installed. Faking it\")\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary library\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pywt\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "from scipy import signal\n",
    "from stingray import lightcurve\n",
    "import sys\n",
    "from stingray import Bispectrum\n",
    "import warnings\n",
    "import csv\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file that will be skipped because of information loss\n",
    "zeros_test = ['co2a0000368_91.csv', 'co2c0000341_26.csv']\n",
    "zeros_train = ['co2a0000368_0.csv', 'co2a0000368_1.csv', 'co2a0000368_2.csv', 'co2a0000368_3.csv', 'co2a0000368_4.csv', 'co2a0000368_5.csv', 'co2c0000341_27.csv']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Menghitung Matriks Cumulant orde ke-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcCumulantOrde3(df_data, t, lag):\n",
    "    # Compute the bispectrum of the signal\n",
    "    lc = lightcurve.Lightcurve(t,df_data.T)\n",
    "    bs = Bispectrum(lc, maxlag=lag)\n",
    "\n",
    "    # Plot the bispectrum using contour plots\n",
    "    # plt.contour(bs.freq, bs.freq, bs.bispec_mag)\n",
    "    # plt.xlabel('f1')\n",
    "    # plt.ylabel('f2')\n",
    "    # plt.show()\n",
    "\n",
    "    # # Plot the bispectrum using mesh plots\n",
    "    # fig = plt.figure()\n",
    "    # ax = fig.add_subplot(111, projection='3d')\n",
    "    # X, Y = np.meshgrid(bs.freq, bs.freq)\n",
    "    # ax.plot_surface(X, Y, bs.bispec_mag)\n",
    "    # ax.set_xlabel('f1')\n",
    "    # ax.set_ylabel('f2')\n",
    "    # ax.set_zlabel('Bispectrum')\n",
    "    # plt.show()\n",
    "\n",
    "    return bs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Melakukan dekomposisi wavelet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcWaveletDec(bs):\n",
    "    # Select wavelet and decomposition level\n",
    "    wavelet = 'db4'\n",
    "    level = 5\n",
    "\n",
    "    # Deecompose signal\n",
    "    coeffs = pywt.wavedec2(bs.cum3, wavelet, level=level)\n",
    "\n",
    "    # print(coeffs)\n",
    "    # Visualize\n",
    "    \n",
    "    cA5 = coeffs[0][np.triu(np.ones_like(coeffs[0], dtype=bool))]\n",
    "    cD5 = np.ravel([coeffs[1][0], coeffs[1][1], coeffs[1][2]])\n",
    "    cD4 = np.ravel([coeffs[2][0], coeffs[2][1], coeffs[2][2]])\n",
    "    cD3 = np.ravel([coeffs[3][0], coeffs[3][1], coeffs[3][2]])\n",
    "    cD2 = np.ravel([coeffs[4][0], coeffs[4][1], coeffs[4][2]])\n",
    "    cD1 = np.ravel([coeffs[5][0], coeffs[5][1], coeffs[5][2]])\n",
    "    \n",
    "    coeff = [cA5,cD5,cD4,cD3,cD2,cD1]\n",
    "    # fig, axs = plt.subplots(6)\n",
    "    \n",
    "    \n",
    "    # axs[0].plot(cA5)\n",
    "    # axs[0].set_title(f'Approximation - Level 5')\n",
    "    # axs[1].plot(cD5)\n",
    "    # axs[1].set_title(f'Detail - Level 5')\n",
    "    # axs[2].plot(cD4)\n",
    "    # axs[2].set_title(f'Detail - Level 4')\n",
    "    # axs[3].plot(cD3)\n",
    "    # axs[3].set_title(f'Detail - Level 3')\n",
    "    # axs[4].plot(cD2)\n",
    "    # axs[4].set_title(f'Detail - Level 2')\n",
    "    # axs[5].plot(cD1)\n",
    "    # axs[5].set_title(f'Detail - Level 1')\n",
    "    # plt.show()\n",
    "\n",
    "    return coeffs\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Menghitung energi relatif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcRelativeEnergy(coeffs, df_data):\n",
    "    # Calculate relative wavelet energy\n",
    "    energies = []\n",
    "    for c in coeffs:\n",
    "        energies.append(np.sum(np.square(c)))\n",
    "\n",
    "    decomp = ['A5', 'D1', 'D2', 'D3', 'D4', 'D5']\n",
    "\n",
    "    energies[1:6] = energies[-1:-6:-1]\n",
    "\n",
    "    total_energy = np.sum(energies)\n",
    "    relative_energies = [(e / total_energy) * 100 for e in energies]\n",
    "\n",
    "    # print(relative_energies)\n",
    "\n",
    "    # plt.plot(decomp, energies)\n",
    "    # plt.xlabel('Dimension Number')\n",
    "    # plt.ylabel('Wavelet Bispectrum Energy')\n",
    "    # plt.show()\n",
    "\n",
    "    # plt.plot(decomp, relative_energies)\n",
    "    # plt.xlabel('Dimension Number')\n",
    "    # plt.ylabel('Relative Wavelet Bispectrum Energy')\n",
    "    # plt.show()\n",
    "\n",
    "    return energies, relative_energies"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persiapan data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sampling frequency\n",
    "fs = 256\n",
    "t = np.arange(0, 1, 1/fs)\n",
    "\n",
    "def get_csv_EEG(filename):\n",
    "    # Load data from CSV\n",
    "    data = np.loadtxt(filename, delimiter=\",\", skiprows=1, usecols=range(3,259))\n",
    "    channel_name = np.loadtxt(filename, delimiter=\",\", skiprows=1, usecols=1, dtype='str', encoding='utf-8')\n",
    "    \n",
    "    df_data = pd.DataFrame(data.T, columns=channel_name)\n",
    "\n",
    "    df_data = df_data.drop(columns=['X', 'Y', 'nd'])\n",
    "\n",
    "    return df_data, df_data.columns\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perhitungan RWB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(directory, lag):\n",
    "    recap = pd.DataFrame(columns=['Wall Time', 'CPU Time'])\n",
    "    for foldername in os.listdir(directory):\n",
    "        folder = os.path.join(directory, foldername)\n",
    "        if os.path.isdir(folder):\n",
    "            des_dir = os.path.join(directory.replace('CSV', 'FEATURE')+\"_\" + str(lag),foldername).lower()\n",
    "            files = os.listdir(folder)\n",
    "            for filename in files:\n",
    "                cpu_start = time.process_time()\n",
    "                wt_start = time.time()\n",
    "                if filename in zeros_train or filename in zeros_test:\n",
    "                    continue\n",
    "                rel_path = os.path.join(directory, foldername, filename)\n",
    "                if 'metadata' in filename.lower():\n",
    "                    continue\n",
    "                trial_number = filename.split('.')[0].split('_')[1]\n",
    "                df_data, channel_name = get_csv_EEG(rel_path)\n",
    "                des_file = foldername+'_'+ str(trial_number) + '_bispectrum' +'.npy'\n",
    "                if not os.path.exists(des_dir):\n",
    "                    os.makedirs(des_dir)\n",
    "                des_path = os.path.join(des_dir, des_file)\n",
    "                if os.path.exists(des_path):\n",
    "                    continue\n",
    "                RWB = []\n",
    "                for channel in channel_name:\n",
    "                    y = df_data[channel]; # sinyal per channel\n",
    "                    # N = len(y);\n",
    "                    # z = y - np.mean(y);\n",
    "                    # nsamp = len (y[0])\n",
    "                    energies, relative_energies = calcRelativeEnergy(calcWaveletDec(calcCumulantOrde3(y, t, lag)), y)\n",
    "                    for x in relative_energies:\n",
    "                        RWB.append(x)\n",
    "                RWB = np.array(RWB)\n",
    "                np.save(des_path, RWB)\n",
    "                wt_end = time.time()\n",
    "                cpu_end = time.process_time()\n",
    "                wall_time = wt_end - wt_start\n",
    "                cpu_time = cpu_end - cpu_start\n",
    "                recap_temp = pd.DataFrame([[wall_time, cpu_time]],columns=recap.columns)\n",
    "                recap = pd.concat([recap, recap_temp], ignore_index=True)\n",
    "                # pd.DataFrame(RWB.T).to_csv(des_path, index=False)\n",
    "    recap_dir = os.path.join('./logs/Execution',directory.split('/')[1])\n",
    "    if not os.path.exists(recap_dir):\n",
    "        os.makedirs(recap_dir)\n",
    "    recap_path = os.path.join(recap_dir,'recap_rwb'+str(lag)+'.csv')\n",
    "    recap.to_csv(recap_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mengecek nilai nol pada data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_zeros(directory):\n",
    "    contain_zero = []\n",
    "    for foldername in os.listdir(directory):\n",
    "        folder = os.path.join(directory, foldername)\n",
    "        if os.path.isdir(folder):\n",
    "            files = os.listdir(folder)\n",
    "            for filename in files:\n",
    "                rel_path = os.path.join(directory, foldername, filename)\n",
    "                if 'metadata' in filename.lower():\n",
    "                    continue\n",
    "                df_data, channel_name = get_csv_EEG(rel_path)\n",
    "                for channel in channel_name:\n",
    "                    if (df_data[channel]== 0).all():\n",
    "                        contain_zero.append(filename)\n",
    "                        break\n",
    "    return contain_zero"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dummy(directory, lag):\n",
    "    for foldername in os.listdir(directory):\n",
    "        folder = os.path.join(directory, foldername)\n",
    "        if os.path.isdir(folder):\n",
    "            des_dir = os.path.join(directory.replace('CSV', 'FEATURE')+\"_\" + str(lag),foldername).lower()\n",
    "            files = os.listdir(folder)\n",
    "            for filename in files:\n",
    "                rel_path = os.path.join(directory, foldername, filename)\n",
    "                if 'metadata' in filename.lower():\n",
    "                    continue\n",
    "                trial_number = filename.split('.')[0].split('_')[1]\n",
    "                df_data, channel_name = get_csv_EEG(rel_path)\n",
    "                RWB = []\n",
    "                return df_data[channel_name[0]]\n",
    "                # pd.DataFrame(RWB.T).to_csv(des_path, index=False)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_dummy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m lag \u001b[39m=\u001b[39m \u001b[39m128\u001b[39m\n\u001b[1;32m----> 2\u001b[0m dummy \u001b[39m=\u001b[39m get_dummy(\u001b[39m'\u001b[39m\u001b[39m../SMNI_CMI_TEST_CSV\u001b[39m\u001b[39m'\u001b[39m, lag)\n\u001b[0;32m      3\u001b[0m relative_energies \u001b[39m=\u001b[39m calcRelativeEnergy(calcWaveletDec(calcCumulantOrde3(dummy, t, lag)), dummy)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_dummy' is not defined"
     ]
    }
   ],
   "source": [
    "lag = 128\n",
    "dummy = get_dummy('../SMNI_CMI_TEST_CSV', lag)\n",
    "relative_energies = calcRelativeEnergy(calcWaveletDec(calcCumulantOrde3(dummy, t, lag)), dummy)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lags = [256, 128, 64, 32, 16, 8, 4, 2]\n",
    "for lag in lags:\n",
    "    extract_feature('../SMNI_CMI_TEST_CSV', lag)\n",
    "    extract_feature('../SMNI_CMI_TRAIN_CSV', lag)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skripsi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7899ebb7610f36207965d38f68f9fcf69ead4646d08358e8b81fddd5bb8ec13e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
